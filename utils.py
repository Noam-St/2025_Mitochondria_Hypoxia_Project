import pandas as pd
import numpy as np
import os
import glob
import re
import random
import snoop
from importlib import reload
from ast import literal_eval

import matplotlib.pyplot as plt
import matplotlib.path as mpath
import matplotlib.patches as mpatches
from matplotlib.patches import Patch
from matplotlib.lines import Line2D
import seaborn as sns

import scipy.stats as stats
from scipy.stats import mannwhitneyu, norm

from sklearn.cluster import KMeans
from statannot import add_stat_annotation
from statannotations.Annotator import Annotator
from Bio import SeqIO, Entrez

import remove_batch_effects as rbe
import flanking_regions as fr
import dna_features_translator_class as dftc
import consts


reload(rbe)
reload(consts)
PATH = os.getcwd()

def genelist(file, mode = 'infer'):
    """
    Generate a dataframe based on a list of genes from a file    
    """
    prefix = os.path.split(file)[-1].replace('.txt', '').replace('.tsv', '')
    if (file.endswith('.txt') and mode == 'infer') or mode == 'txt':
        with open(file) as f:
            genes = f.read().splitlines()
        df = pd.DataFrame({'gene':genes, 'Description' : [prefix for _ in genes]})
    elif (file.endswith('.tsv') and mode == 'infer') or mode == 'tsv':
        df = pd.read_csv(file, delimiter='\t')
        df['Description'] = prefix
    return df

def genelist_on_folder(folder, mode = '.txt'):
    """
    Generate a dataframe based on a list of genes from a folder
    """
    files = os.listdir(rf'{folder}')
    if mode == '.txt':
        files = [f for f in files if f.endswith('.txt')]
    elif mode == '.tsv':
        files = [f for f in files if f.endswith('.tsv')]
    df = pd.DataFrame()
    for i, file in enumerate(files):
        if i == 0:
            df = genelist(os.path.join(folder, file))
        else:
            df = pd.concat([df, genelist(os.path.join(folder, file))])
    return df

def make_volcanoplot(df, cat_col, cat, lfc, pv, geneid, show = False, pval_cutoff = 0.05, lfc_cutoff = 1, figprefix = 'volcano', figtype = 'pdf'):
    """
    Based on a deseq csv, create a volcano plot of all genes within the category
    """
    df_cat = df[df[cat_col] == cat]
    df_cat = df_cat.sort_values(by = pv, ascending = True)
    visuz.GeneExpression.volcano(df = df_cat,
    lfc = lfc,
    pv = pv,
    geneid = geneid,
    gstyle = 2,
    sign_line = True,
    axlabelfontsize = 10,
    geneprefixs = ({k:k for k in df_cat[geneid] if 
                  (df_cat.loc[df_cat[geneid] == k, pv].iloc[0] < pval_cutoff) and\
                  (abs(df_cat.loc[df_cat[geneid] == k, lfc].iloc[0]) > lfc_cutoff)}),
    show = show,
    figprefix = figprefix,
    figtype = figtype)

def generate_2_x_2_conting(
    df,
    row_cat = 'Alter_model',
    comparison_cat = 'strand_switch',
    col_cat_A = 'DSJ',
    col_cat_B = 'SSJ',
    group_factor = 'org',
    cont_factor = 'junc_tpm'):
    """
    Generate a 2x2 chi_squared table for the following factors: significant/non significant and the row_cat.
    The p-values are generated by comparing the cont_factor values between two categories of comparison_cat for each group_factor category.
    """
    AGC_list = []
    non_AGC_list = []
    alpha = 0.05/len(df[group_factor].unique())
    for i in df[group_factor].unique():
        grp_1 = df.loc[(df[comparison_cat] == col_cat_A) & (df[group_factor] == i), cont_factor]
        grp_2 = df.loc[(df[comparison_cat] == col_cat_B) & (df[group_factor] == i), cont_factor]
        AGC = df.loc[df[group_factor] == i, row_cat].iloc[0].squeeze()
        sign = mannwhitneyu(grp_1, grp_2, alternative = 'less').pvalue < alpha
        if AGC:
            AGC_list.append(sign)
        else:
            non_AGC_list.append(sign)
    return np.array([[sum(AGC_list), len(AGC_list) - sum(AGC_list)], [sum(non_AGC_list), len(non_AGC_list) - sum(non_AGC_list)]])

def split_grab(string, delimiter = '>', n = 1):
    """
    Split a string by a delimiter and return the nth element if exists, otherwise return an empty string
    """
    try:
        return string.split(delimiter)[n]
    except IndexError:
        return ''

def prepare_metadata(id_col, label_col, label_list, df, sep = '_'):
    """
    Prepare a metadata df based on EBI's tsv files

    Parameters
    ----------
    id_col : str
        The prefix of the column containing the ids.
    label_col : str
        The prefix of the column containing the labels.
    df : pandas.DataFrame
        The dataframe containing the data.
    sep : str (default: '_')
        The separator used in the metadata file.
    label_list : list
        The list of labels to be used.

    Returns
    -------
    pandas.DataFrame
        The dataframe containing the metadata.
    """
    # Subset only the relevant columns
    metadata = df[[id_col, label_col]].copy()
    # Split the labels into a list based on a given separator
    params = metadata[label_col].apply(lambda x : re.split(sep, x))
    # If the params lists have different lengths, pad them with empty strings in the same position
    params = params.apply(lambda x: x + [np.nan] * (len(label_list) - len(x)))
    # Modify the dataframe
    for i, _ in enumerate(params[0]):
        metadata[label_list[i]] = [j[i] for j in params]
    # Drop the old column
    metadata.drop(label_col, axis = 1, inplace = True)
    return metadata

def prepare_counts(folder, min_read_sum = 1000, keep_symbol = False, keep_suffix = False, suffix_ind = 0):
    """
    Prepare count table for DEseq2 analysis based on a folder of htseq count files

    Parameters
    ----------
    folder : str
        The folder containing the htseq count files.
    min_read_sum : int (default: 1000)
        The minimum read sum to be considered.
    keep_symbol : bool (default: False)
        Whether to keep the symbol column or not.
    suffix : bool (default: False)
        Whether to keep the suffix of the file name or not.

    Returns
    -------
    pandas.DataFrame
        The dataframe containing the counts.
    """
    # Get the files
    paths = glob.glob(os.path.join(folder, '*.txt'))
    c_list = []
    # Iterate over the files in paths
    for i, path in enumerate(paths):
        # Get the suffix
        if not keep_suffix: suffix = os.path.split(path)[-1].split('_')[suffix_ind]
        else: suffix = os.path.split(path)[-1].split('.')[suffix_ind]
        # Load the count dfs
        try:
            count_df = pd.read_csv(path, sep = '\t', header = None)
        except pd.errors.EmptyDataError:
            continue
        # Check col count
        if len(count_df.columns) > 2: # If there are more than 2 columns, assume that there is a symbol column
            count_df.columns = ['id', 'symbol', suffix]
        elif len(count_df.columns) == 2: # If there are only 2 columns, assume that there is no symbol column
            count_df.columns = ['id', suffix]
        else:
            raise ValueError('Invalid column count') # If there are less than 2 columns, raise an error
        # Check the read sum
        if count_df[suffix].sum() < min_read_sum:
            print('{} has too few reads!\n read sum = {}'.format(suffix, count_df[suffix].sum()))
            continue
        # Remove __no_feature etc
        count_df = count_df[~count_df['id'].str.contains('__')]
        # Sort by id
        count_df.sort_values('id', inplace = True)
        # Set ID as index
        count_df.set_index('id', inplace = True)
        if keep_symbol and i == 0:
            c_list.append(count_df['symbol'])
        # Add current countfile to the list
        c_list.append(count_df[suffix])
    # Concatenate the counts
    counts = pd.concat(c_list, axis = 1)
    return counts

def prepare_deseq(path, prefix = 'gene', id_col = 'id', gene_col = 'name', sep = ','):
    """
    Prepare a DEseq2 result file for plotting and add gene annotation information (such as associated OXPHOS complex)

    Parameters
    ----------
    path : str  
        The path to the DEseq2 result file.
    prefix : str (default: 'gene')
        The prefix of the columns in the DEseq2 result file.
    id_col : str (default: 'id')
        The name of the column containing the gene ids.
    gene_col : str (default: 'name')
        The name of the column containing the gene names.
    
    Returns
    -------
    pandas.DataFrame
        The dataframe containing the DEseq2 results.
    """
    if prefix != '': # If there is a name prefix, add it to the column names
        prefix = prefix.replace('\.','') + '.'
    deseq = pd.read_csv(path, sep = sep) # Load the deseq file
    if deseq.shape[1] == 1: # If there is only one column, read first column as index
        deseq = pd.read_csv(path, index_col = 0)
    deseq[f'{prefix}log2FoldChange'] = deseq[f'{prefix}log2FoldChange'].fillna(0) # Fill NaNs with 0
    deseq[f'{prefix}padj'] = deseq[f'{prefix}padj'].fillna(0.99) # Fill NaNs with 0.99
    deseq[f'{prefix}{id_col}'] = deseq[f'{prefix}{id_col}'].str.split('.').str[0] # Remove the transcript.id suffix
    gene_col = prefix + gene_col
    #txtgenes = genelist_on_folder(os.path.join(PATH, 'data', 'genes'), mode = '.txt') # Get the list of gene files
    tsvgenes = genelist_on_folder(os.path.join(PATH, 'data', 'genes'), mode = '.tsv').drop(columns = ['Other_Names', 'Protein_type', 'Subunit_Name', 'Subunit'])
    #deseq = deseq.merge(txtgenes, how = 'left', left_on = gene_col, right_on = 'gene' )
    deseq = deseq.merge(tsvgenes, how = 'left', left_on = gene_col, right_on = 'Name', suffixes = ['_txt', '_tsv']).drop(columns = ['Ensembl_ID', 'Name'])
    #deseq['Complex'] = np.where(deseq['Description_txt'] == 'mtRibosome', 'Ribosome', deseq['Complex'])
    return deseq

def combine_counts_metadata(counts_path, metadata_path, results_path, metadata_id_col = 'run_accession', batch_correction = False, batch_cols = ['replicate']):
    tsvgenes = genelist_on_folder(os.path.join(PATH, 'data', 'genes'), mode = '.tsv').drop(columns = ['Other_Names', 'Protein_type', 'Subunit_Name', 'Subunit', '5.67529814124456', 'From', 'To', 'STC1']).dropna(subset = 'Name')
    if type(counts_path) == str:
        counts = pd.read_csv(counts_path, index_col = 0)
    else:
        counts = counts_path
    # Convert genes to uppercase
    counts.index = counts.index.str.upper()
    # Remove batches if batch_correction is True

    if type(metadata_path) == str:
        metadata = pd.read_csv(metadata_path, index_col = 0)
    else:
        metadata = metadata_path

    if type(results_path) == str:
        results = pd.read_csv(results_path, index_col = 0)
    else:
        results = results_path

    # Convert counts to long format
    counts = counts.reset_index(names = ['gene']).set_index('gene')
    if batch_correction:
        counts, _ = rbe.main(counts, metadata.reset_index(), id_col = 'gene', batch_cols = batch_cols, sample_col = metadata_id_col)
    counts = counts.reset_index()
    counts = counts.melt(id_vars = 'gene', var_name = 'sample', value_name = 'count')
    results = results.reset_index(names = ['gene'])
    # Convert counts to long format and combine with metadata
    counts = counts.merge(metadata, left_on = 'sample', right_on = metadata_id_col, how = 'left')
    # Merge with gene list
    counts = counts.merge(tsvgenes, left_on = 'gene', right_on = 'Name', how = 'left')
    results = results.merge(tsvgenes, left_on = 'gene', right_on = 'Name', how = 'left')
    # Add genome column
    counts['Genome'] = 'NUC'
    results['Genome'] = 'NUC'
    counts.loc[counts['gene'].isin(consts.MT_GENES + consts.MT_GENES_NO_PREFIX), 'Genome'] = 'MT'
    results.loc[results['gene'].isin(consts.MT_GENES + consts.MT_GENES_NO_PREFIX), 'Genome'] = 'MT'
    # Print the number of genes in each genome
    print(counts[counts['count'].notna()].groupby('Genome').agg({'gene':'nunique'}))
    return counts, metadata, results

def combine_counts(counts_path, metadata_path):
    """
    Combine the counts from multiple count_tables into a long-format dataframe with the metadata and info on OXPHOS genes
    """
    counts_path = os.path.join(counts_path, '*.csv')
    metadata_path = os.path.join(metadata_path, '*.csv')
    counts = glob.glob(counts_path)
    metadata_paths= glob.glob(metadata_path)
    count_dfs = []
    metadata_dfs =[]
    for i in metadata_paths:
        metadata_df = pd.read_csv(i)
        metadata_df['dataset'] = os.path.split(i)[-1].split('.')[0]
        metadata_dfs.append(metadata_df)
    metadata_df = pd.concat(metadata_dfs)
    # Fill NAs in run_accession column with the values of sample_accession
    if 'sample_accession' in metadata_df.columns:
        metadata_df['run_accession'] = metadata_df['run_accession'].fillna(metadata_df['sample_accession'])
    if 'Sample_Name' in metadata_df.columns:
        metadata_df['run_accession'] = metadata_df['run_accession'].fillna(metadata_df['Sample_Name'])
    for count_path in counts:
        count_df = pd.read_csv(count_path, index_col = 0)
        count_df = count_df.reset_index().melt(id_vars = 'index', value_name = 'counts', var_name = 'sample').rename(columns = {'index':'gene'})
        count_df = count_df.merge(metadata_df, right_on = 'run_accession', left_on = 'sample', how = 'left').merge(consts.GENELIST_DF, left_on = 'gene', right_on = 'Name', how = 'left')
        # Drop columns that are only na
        count_df = count_df.dropna(axis = 1, how = 'all').rename(columns = {'sample_x':'sample', 'condition': 'treatment', 'Treatment' : 'treatment', 'cell':'cell_type', 'cell_line' : 'cell_type'})
        count_df = count_df.replace(consts.UNIFY_DICT)
        count_df['Genome'] = 'NUC'
        count_df.loc[count_df['gene'].isin(consts.MT_GENES), 'Genome'] = 'MT'
        count_df['dataset'] = os.path.split(count_path)[-1].split('.')[0]
        try: 
            count_df['treatment'] = count_df['treatment'].str.capitalize()
        except KeyError:
            print(f'No treatment column in {count_path}')
        count_df['log2_counts'] = np.log2(count_df['counts'] + 1)
        # Add a cell_type column if it is missing
        if 'cell_type' not in count_df.columns:
            count_df['cell_type'] = os.path.split(count_path)[-1].split('_')[1]
        count_dfs.append(count_df)
    count_df = pd.concat(count_dfs)
    count_df = count_df.dropna(subset = 'treatment')
    # Remove samples where the treatment value is None
    count_df = count_df[count_df['treatment'] != 'None']
    return count_df

def combine_result_files(results_path):
    """
    Combine several result csvs generated by DESeq2 into a single dataframe
    """
    results = glob.glob(os.path.join(results_path, '*.csv'))
    dfs = []
    for file in results:
        df = pd.read_csv(file, index_col = 0)
        df = df.reset_index().rename(columns = {'index': 'Name'})
        name = os.path.split(file)[-1].split('.')[0].replace('res_', '')
        df['dataset'] = name
        df['cell_line'] = name.split('_')[0]
        dfs.append(df)
    results_df = pd.concat(dfs) 
    results_df = results_df.merge(consts.GENELIST_DF, on = 'Name',  how = 'left')
    return results_df
  
def filter_by_peppr(qa_df):
    """
    Filter the input PEPPRO quality metric df based on the ranges defined in consts.PEPPRO_RANGES
    """
    # Get the ranges
    ranges = consts.PEPPRO_RANGES
    # Filter the df
    for col in ranges:
        # Set col type to float
        qa_df[col] = qa_df[col].astype(float)
        qa_df = qa_df[(qa_df[col] >= ranges[col][0]) & (qa_df[col] <= ranges[col][1])]
    return qa_df

def plot_gene_list(
    dfs, prefixes, names, gene_list, gene_list_name, gene_col = 'gene', gene_cat_col = 'Complex', savefig=True, figsize = (5,6), against_bg = True, random_bg = False, gene_name_df = [], sign_only = False, custom_order = []):
    """
    Iterate over all lfc dfs in the dfs list and plot the Log2FoldChange of the genes in the gene_list.
    Mark significant genes in green and insignificant genes in red.
    The gene_list_name will be used as the title of the plot and the plot file name along with the sample name provided in the names list.

    Parameters
    ----------
    dfs : list
        A list of dataframes containing the Log2FoldChange values.
    prefixes : list
        A list of prefixes to be used for each of the columns.
    names : list
        A list of names to be used for each sample.
    gene_list : list
        A list of genes to be plotted.
    gene_list_name : str
        The name of the gene list to be used as the title of the plot and the plot file name.
    
    Returns
    -------
    None
    """
    if prefixes == None:
        prefixes = [''] * len(dfs)
    green_dot = Line2D([0], [0], linestyle = 'none', marker = 'o', color = 'green', alpha = .5)
    red_dot = Line2D([0], [0], linestyle = 'none', marker = 'o', color = 'red', alpha = .5)
    plt.style.use('default')
    # Create a figure with a subplot for each sample
    fig, axs = plt.subplots(len(dfs), 1,figsize = figsize, sharex = True)
    for i, deseq in enumerate(dfs):
        if (type(axs) == list) or (type(axs) == np.ndarray):
            ax = axs[i]
        else:
            ax = axs
        # Get the medians from the background dfs
        deseq = deseq.loc[:, ~deseq.columns.duplicated()]
        hyp = deseq[deseq[gene_col].isin(gene_list)]    
        hyp = hyp.drop_duplicates(subset = gene_col)        
        if len(gene_name_df) > 0:
            hyp[gene_col] = hyp[gene_col].map(gene_name_df.set_index('drosophila')[gene_col])
            hyp['Complex'] = hyp[gene_col].map(gene_name_df.set_index(gene_col)['complex'])
        hyp['significant'] = hyp[f'{prefixes[i]}padj'] < 0.05
        # Replace True with green and False with red
        hyp['significant'] = hyp['significant'].map({True: 'green', False: 'red'})
        if sign_only:
            hyp = hyp[hyp['significant'] == 'green']
        
        hyp['Complex'] =  hyp['Complex'].astype(pd.CategoricalDtype(categories = consts.COMPLEX_ORDER, ordered = True))
        hyp = hyp.sort_values(by = ['Complex', f'{prefixes[i]}log2FoldChange'], ascending = [True, False])
        if custom_order != []:
            hyp = hyp.set_index(gene_col).loc[custom_order].reset_index()
        t = hyp[hyp['significant'] == 'green']
        f = hyp[hyp['significant'] == 'red']
        ax.errorbar(x = hyp[gene_col], y = hyp[f'{prefixes[i]}log2FoldChange'], yerr = hyp[f'{prefixes[i]}lfcSE'], c = 'green', fmt = 'o', ecolor = 'black', alpha = 0)
        ax.errorbar(x = t[gene_col], y = t[f'{prefixes[i]}log2FoldChange'], yerr = t[f'{prefixes[i]}lfcSE'], c = 'green', fmt = 'o', ecolor = 'black',  label = '' if sign_only else 'Significant')
        if not sign_only:
            ax.errorbar(x = f[gene_col], y = f[f'{prefixes[i]}log2FoldChange'], yerr = f[f'{prefixes[i]}lfcSE'], c = 'red', fmt = 'o', ecolor = 'black', label = 'Not significant')
        if against_bg:
            bg = deseq[~deseq[gene_col].isin(gene_list)]
            bg = bg.drop_duplicates(subset = gene_col)
            if sign_only:
                bg = bg[bg[f'{prefixes[i]}padj'] < 0.05]
            if random_bg:
                bg[gene_cat_col] = np.random.choice(bg[gene_cat_col], len(bg), replace = False)
            bg_group = bg.groupby(gene_cat_col).agg({f'{prefixes[i]}log2FoldChange': ['mean', 'std']})
            bg_group.columns = bg_group.columns.droplevel(0)
            bg_group = bg_group.reset_index()
            # Add the median values or each complex to the hyp df
            hyp = hyp.merge(bg_group, on = gene_cat_col, how = 'left')
            # Plot these values
            ax.errorbar(x = hyp[gene_col], y = hyp['mean'], yerr = hyp['std'], c = 'black', fmt = 'o', ecolor = 'black', alpha = 0.3, label = 'nDNA background')
        ax.axhline(y = 0, color = 'black', linestyle = '--', linewidth = .5)
        # despine the top and right spines using plt
        ax.spines['right'].set_visible(False)
        ax.spines['top'].set_visible(False)
        # Flip the x axis 90 degrees
        # Remove grid
        ax.grid(False)
        ax.set_title(f'{names[i]}')
    # Set legend outside the plot
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 8)
    ax.set_ylabel('logFC', fontsize = 10)
    ax.set_xlabel('Genes', fontsize = 10)
    plt.xticks(rotation = 45)
    plt.tight_layout(pad = 0.5)

    if savefig: plt.savefig(os.path.join(PATH, 'figures', f'{names[i]}_{gene_list_name}_fc.png'), dpi = 300, bbox_inches = 'tight')

def plot_expr_gene_list(counts, gene_list, gene_col = 'gene', count_col = 'counts', fact_col = 'treatment', dat_col = None):
    """
    Receive a count df and a list of genes. Plot the normalized expression of gene in list for each treatment in fact_col. Additionally, if the create a subplot for each dataset in dat_col.
    """
    pass

def custom_annot_plot(
        plot = 'boxplot', test_type = 'Mann-Whitney', loc = 'inside', box_pairs = [('DSJ','SSJ')],
        t_format = 'star', xlabel = 'Strand switched', ylabel = 'log(expression)', savefig = False, style = 'default', despine = True, *args, **kwargs):
    """
    Recieve a FacetPlot object, create a boxplot with **kwargs and use add_stat_annotation to perform a statistical test.

    Parameters
    ----------
    test_type :
        (Default value = 'Mann-Whitney') The statistical test to perform
    loc :
        (Default value = 'inside') The location of the annotation
    box_pairs :
        (Default value = [('DSJ') ('SSJ')]) The list of box pairs to perform the statistical test on
    'SSJ')] :
        
    t_format :
        (Default value = 'star') The format of the annotation
    xlabel :
        (Default value = 'Strand switched') The xlabel of the boxplot
    ylabel :
        (Default value = 'log(expression)') The ylabel of the boxplot
    **kwargs : 
        The kwargs to pass to FacetGrid.map_dataframe
    """
    plt.style.use(style)
    plot_dict = {'boxplot': sns.boxplot, 'violinplot': sns.violinplot, 'stripplot': sns.stripplot, 'swarmplot': sns.swarmplot, 'pointplot': sns.pointplot, 'barplot': sns.barplot, 'boxenplot': sns.boxenplot, 'countplot': sns.countplot, 'pointplot': sns.pointplot}
    print(kwargs['data'])
    try: ax = plot_dict[plot](*args, **kwargs)
    except KeyError: print(f'Please select a valid plot type: {list(plot_dict.keys())}')
    # If kwargs['hue'] exists, add the hue to the box_pairs
    if 'hue' in kwargs.keys():
        add_stat_annotation(
        ax, plot = plot, data=kwargs['data'], x=kwargs['x'], y=kwargs['y'], hue = kwargs['hue'],
        box_pairs=box_pairs,
        test = test_type, loc = loc,
        text_format = t_format,
        verbose = 2
        )
    else:
        add_stat_annotation(
        ax, plot = plot, data=kwargs['data'], x=kwargs['x'], y=kwargs['y'],
        box_pairs=box_pairs,
        test = test_type, loc = loc,
        text_format = t_format,
        verbose = 2
        )
    if despine:
        sns.despine(ax = ax, offset = 10, trim = False)
     
def plot_mt_vs_nuc(counts, x = 'treatment', y = 'count', hue = 'Genome', control = 'Normoxia', treatment = 'Hypoxia', nuc_name = 'NUC', mt_name = 'MT', oxphos = True, savefig = '', test = 'Mann-Whitney', test_format = 'star', verbose = 0, stat_loc = 'outside', figsize = (4,4), hyp_time = '24h', hyp_conc = '', species = '', dodge = False, mode = 'pointplot'):
    """
    """
    if oxphos:
        counts = counts[(counts['Complex'].notna()) | (counts['Genome'] == 'MT')]
        # Report how many genes are in each complex and each genome
        print(counts.groupby(['Complex', 'Genome'], dropna=False).agg({'gene':'nunique'}))
    # Calculate z-score
    counts['z-score'] = counts.groupby([hue])[y].transform(lambda x: (x - x.mean()) / x.std())
    _, ax = plt.subplots(figsize = figsize)
    counts = counts.replace({control : 'Normoxia', treatment : 'Hypoxia'})
    control, treatment = 'Normoxia', 'Hypoxia'
    if mode == 'pointplot':
        sns.pointplot(data = counts, x = x, y = 'z-score', hue = hue, hue_order = [nuc_name, mt_name], dodge = dodge, errorbar = 'se', ax = ax, order = [control, treatment], palette=['tab:green', 'tab:red'])
        # Add statistical test
        pairs = [((control, nuc_name), (treatment, nuc_name)), ((control, mt_name), (treatment, mt_name))]
        print(pairs)
        # Set legend outside of plot
        ax.legend(title = hue, bbox_to_anchor=(1.05, 1), loc='upper left')
        add_stat_annotation(ax, data = counts, x = x, y = 'z-score', hue = hue, box_pairs = pairs, test = test, text_format = test_format, loc = stat_loc, verbose = verbose, line_height=0.05)
    elif mode == 'boxplot':

        sns.boxplot(data = counts, x = hue, y = 'z-score', hue = x, hue_order = [control, treatment], ax = ax, palette=['tab:green', 'tab:red'], order = [nuc_name, mt_name])
        pairs = [((nuc_name, control), (nuc_name, treatment)), ((mt_name, control), (mt_name, treatment))]
        # Set legend outside of plot
        ax.legend(title = x, bbox_to_anchor=(1.05, 1), loc='upper left')
        sns.stripplot(data = counts, x = hue, y = 'z-score', hue = x, hue_order = [control, treatment], ax = ax, palette=['grey', 'grey'], order = [nuc_name, mt_name], size = 1.5, alpha = .3, dodge = True, legend=False)

        add_stat_annotation(ax, data = counts, x = hue, y = 'z-score', hue = x, box_pairs = pairs, test = test, text_format = test_format, loc = stat_loc, verbose = verbose, line_height=0.05)
    else:
        print(f'Invalid mode: {mode}\nPlease choose one of the following: pointplot, boxplot')
    # Change the alpha of the error bars
    for line in ax.lines:
        line.set_alpha(0.4)
    # Increase x ticklabel size
    ax.set_xticklabels(ax.get_xticklabels(), fontsize = 12)
    ax.set_xlabel('')
    ax.set_ylabel('Scaled Expression')
    sns.despine()
    # Set title outside the plot
    plt.suptitle(f'{species} {hyp_conc} for {hyp_time}', y = .95)
    plt.tight_layout()
    if savefig != '':
        plt.savefig(os.path.join(PATH, 'Hypoxia_across_evolution', 'figures', f'{species}_{hyp_conc}_{hyp_time}_{nuc_name}_vs_{mt_name}.png'), dpi = 300, bbox_inches = 'tight')

def replace_with_ortho(counts_path, ortho_df, ortho_col, override = True):
    """
    Recieve a counts df of a species, replace the gene names with the orthologous gene names from ortho_df
    """
    counts = pd.read_csv(counts_path, index_col = 0)
    ortho_df = ortho_df.drop_duplicates(subset = ortho_col)[['Gene name', ortho_col]]
    counts = counts.merge(ortho_df, left_index=True, right_on = ortho_col, how = 'left')
    counts['Gene name'] = np.where(counts['Gene name'].isna(), counts[ortho_col], counts['Gene name'])
    counts = counts.set_index('Gene name')
    counts = counts.drop(columns = ortho_col)
    if override:
        counts.to_csv(counts_path)
    else:
        counts.to_csv(counts_path.replace('.csv', '_ortho.csv'))

def mitonuclear_coordination(results_df, mt_gene_thresh = 5, nuc_gene_thresh = 10, dataset_col = 'dataset', padj_thresh = .05, genes = 'both', lfc_col = 'log2FoldChange'):
    """
    Recieve a combined results_df, for each dataset, determine if the mitonuclear expression is coordinated for OXPHOS genes and return three lists, coord list, uncoord list and unassigned list
    
    Parameters
    ----------
    genes : str
        (Default value = 'both') The type of genes to consider, can be 'OXPHOS', 'Ribosome' or 'both'
    """
    # Assign the datasets to coordinated and uncoordinated. In coordinated, the log2FC of significant OXPHOS genes in MT and NUC are in the same direction. In uncoordinated, the log2FC of significant OXPHOS genes in MT and NUC are in the opposite direction.

    results_df_sign = results_df[results_df['padj'] < padj_thresh].copy()
    if genes == 'OXPHOS':
        results_df_sign_oxphos = results_df_sign.loc[(results_df_sign['Complex'].isin(['I', 'II', 'III', 'IV', 'V'])), :].copy()
        N_NUC = consts.N_NUC_OXPHOS_GENES
        N_MT = consts.N_MT_OXPHOS_GENES
    elif genes == 'Ribosome':
        results_df_sign_oxphos = results_df_sign.loc[(results_df_sign['Complex'] == 'Ribosome'), :].copy()
        N_NUC = consts.N_NUC_RIBOSOME_GENES
        N_MT = consts.N_MT_RIBOSOME_GENES
    else: 
        results_df_sign_oxphos = results_df_sign.loc[(results_df_sign['Complex'].notna()) | (results_df_sign['Genome'] == 'MT'), :].copy()
        N_NUC = consts.N_NUC_OXPHOS_GENES + consts.N_NUC_RIBOSOME_GENES
        N_MT = consts.N_MT_OXPHOS_GENES + consts.N_MT_RIBOSOME_GENES
    count = 0
    coordinated = []
    uncoordinated = []
    unassigned = []
    coord_mag_dict = {}
    nuc_mag_dict = {}
    mt_mag_dict = {}
    for dataset in results_df_sign_oxphos.dataset.unique():
        cur_df = results_df_sign_oxphos.loc[results_df_sign_oxphos['dataset'] == dataset, :]
        mt_genes = cur_df.loc[cur_df['Genome'] == 'MT',:].sort_values(by = lfc_col, ascending = False)
        nuc_genes = cur_df.loc[cur_df['Genome'] == 'NUC',:].sort_values(by = lfc_col, ascending = False)
        mt_genes_count = len(mt_genes)
        nuc_genes_count = len(nuc_genes)

        # Calculate the mean of the sign function of log2fc of the genes, this is to determine the mean direction of the genes regardless of the log2fc magnitude
        mt_genes_mean = np.sign(mt_genes[lfc_col]).mean()
        nuc_genes_mean = np.sign(nuc_genes[lfc_col]).mean()
        coord = mt_genes_mean * nuc_genes_mean
        # If any of the genes are lower than threshold, continue
        if mt_genes_count < mt_gene_thresh or nuc_genes_count < nuc_gene_thresh:
            print(f'Not enough {genes} genes in {dataset} (MT: {mt_genes_count}, NUC: {nuc_genes_count}). Skipping...')
            count += 1
            unassigned.append(dataset)
        elif coord > 0:
            coordination = 'Coordinated'
            coordinated.append(dataset)
            # Proportion of genes that have the same sign as coord
        elif coord <= 0:
            coordination = 'Uncoordinated'
            uncoordinated.append(dataset)
            # Proportion of genes that have the same sign as coord
        #old_coord_mag = abs(sum(np.sign(mt_genes['log2FoldChange'])) + sum(np.sign(nuc_genes['log2FoldChange']))/len(mt_genes))
        
        # Magnitude of coordination, defined as the product of the difference between the number of genes with significant positive and negative genes in MT and NUC separately, divided by the total number of genes in MT and NUC 
        n_up_nuc = len(nuc_genes[nuc_genes[lfc_col] > 0])
        n_down_nuc = len(nuc_genes[nuc_genes[lfc_col] < 0])
        n_up_mt = len(mt_genes[mt_genes[lfc_col] > 0])
        n_down_mt = len(mt_genes[mt_genes[lfc_col] < 0])
        nuc_mag = (n_up_nuc - n_down_nuc) / N_NUC
        mt_mag = (n_up_mt - n_down_mt) / N_MT
        # Coordination magnitude calculation: the product of the magnitude of the difference between the number of genes with significant positive and negative genes in MT and NUC separately, divided by the total number of genes in MT and NUC and the sign of the coordination (values need to be negative if the nuc_mag and mt_mag have different signs).
        coord_mag = abs(nuc_mag * mt_mag) * np.sign(nuc_mag * mt_mag)
        nuc_mag_dict[dataset] = abs(nuc_mag)
        mt_mag_dict[dataset] = abs(mt_mag)
        coord_mag_dict[dataset] = coord_mag

    # Print an overall report
    print(f'Out of {len(results_df_sign_oxphos.dataset.unique())} datasets, {count} datasets were skipped due to insufficient genes.')
    print(f'{len(coordinated)} datasets were coordinated, and {len(uncoordinated)} datasets were uncoordinated.')
    print(f'The magnitude of coordination was {np.mean(list(coord_mag_dict.values())):.2f} +- {np.std(list(coord_mag_dict.values())):.2f}')
    return coordinated, uncoordinated, unassigned, coord_mag_dict, nuc_mag_dict, mt_mag_dict

def plot_gene_counts(df, gene, x = 'treatment', y = 'counts', figsize = (3,3), gene_col = 'gene', set_title = '', control = 'Normoxia', treatment = 'Hypoxia', savefig = ''):
    """
    Plot the counts of a gene across treatments
    """
    if len(df[df[gene_col] == gene]) == 0:
        print(f'{gene} does not exist in the dataframe')
        return
    _, ax = plt.subplots(figsize = figsize)
    df = df[df[gene_col] == gene].copy()
    df[x] = df[x].replace({control : 'Normoxia', treatment : 'Hypoxia'})
    conditions = df[x].unique().tolist()
    order = ['Normoxia', 'Hypoxia']
    pairs = [(conditions[i], conditions[j]) for i in range(len(conditions)) for j in range(i+1, len(conditions))]
    # Order control before treatment
    
    sns.barplot(x = x, y = y, data = df, ax = ax, color = 'grey', order = order)
    print(pairs)
    add_stat_annotation(ax, data = df, x = x, y = y, box_pairs = pairs, test = 'Mann-Whitney', text_format = 'star', loc = 'inside', fontsize = 'large', verbose = 2, comparisons_correction = 'bonferroni', order = order)
    if set_title == '':
        ax.set_title(gene)
    else:
        ax.set_title(set_title)
    ax.set_ylabel('Normalized counts', fontsize = 10)
    ax.set_xlabel('')
    # Rotate x ticklabels
    #plt.xticks(rotation = 45)
    sns.despine()
    ax.grid(False)
    plt.tight_layout()
    if savefig != '':
        plt.savefig(os.path.join(PATH, 'Hypoxia_across_evolution', 'figures', f'{savefig}.png'), dpi = 300, bbox_inches = 'tight')

def create_gene_set_matrix(df, path_to_genelist, gene_col = 'gene', dataset_col = 'dataset', mode = 'infer', PROP = 0.5, return_format = 'matrix', threshold = .05):
    """
    Create a gene set matrix dataframe based on a given genelist and return it
    """
    # Load the genelist
    gene_list = genelist(path_to_genelist, mode = mode).rename(columns = {gene_col : 'gene'})
    # Remove duplicate symbols from genelist
    gene_list = gene_list.drop_duplicates(subset = 'gene')
    # Drop the value "gene", if exists and convert to to list
    gene_list = gene_list[gene_list['gene'] != 'gene'].gene.unique().tolist()
    # Upper list
    gene_list = [i.upper() for i in gene_list]
    # Get the number of genes in the list
    gene_df = df[df['gene'].isin(gene_list)].copy()
    #n_genes = len(gene_df.gene.unique())
    n_genes = len(gene_df.gene.unique())

    dataset_dict = {dataset_col : [], 'cell_line' : [], 'Oxygen Concentration' : [], 'up' : [], 'down' : [], 'nonsign' : [], 'total' : [], 'mean_lfc' : [], 'oxphos_coordination_value' : [], 'tfam_lfc' : [], 'lombardi_hindex' : [], 'oxphos_lfc' : [], 'oxphos_mitochondrial_value' : [], 'oxphos_nuclear_value' : []}
    for dataset in gene_df.dataset.unique():
        cur = gene_df[gene_df[dataset_col] == dataset].copy()
        up = round((len(cur[(cur['log2FoldChange'] > 0) & (cur['padj'] < 0.05)])), 2)
        down = round((len(cur[(cur['log2FoldChange'] < 0) & (cur['padj'] < 0.05)])), 2)
        dataset_dict[dataset_col].append(dataset)
        dataset_dict['oxphos_lfc'].append(cur['oxphos_lfc'].iloc[0])
        dataset_dict['cell_line'].append(cur.cell_line.iloc[0])
        dataset_dict['Oxygen Concentration'].append(cur['Oxygen Concentration'].iloc[0])
        dataset_dict['lombardi_hindex'].append(cur['lombardi_hindex'].iloc[0])
        dataset_dict['oxphos_mitochondrial_value'].append(cur['oxphos_mitochondrial_value'].iloc[0])
        dataset_dict['oxphos_nuclear_value'].append(cur['oxphos_nuclear_value'].iloc[0])
        dataset_dict['up'].append(up)
        dataset_dict['down'].append(down)
        dataset_dict['nonsign'].append(100 - up - down)
        dataset_dict['total'].append(n_genes)
        dataset_dict['mean_lfc'].append(cur.loc[: ,'log2FoldChange'].median())
        if 'oxphos_coordination_value' in cur.columns:
            dataset_dict['oxphos_coordination_value'].append(cur['oxphos_coordination_value'].iloc[0])
        else:
            dataset_dict['oxphos_coordination_value'].append(np.nan)
        if 'tfam_lfc' in cur.columns:
            dataset_dict ['tfam_lfc'].append(cur['tfam_lfc'].iloc[0])
        else:
            dataset_dict ['tfam_lfc'].append(np.nan)
    dataset_df = pd.DataFrame(dataset_dict)
    dataset_df['up+down']= dataset_df['up'] + dataset_df['down']
    dataset_df['max_pct'] = 100
    gene_df = gene_df[gene_df['padj'] < threshold] 
    if return_format == 'matrix':
        df_mat = df.pivot_table(index = 'gene', columns = dataset_col, values = 'log2FoldChange')
        df_mat = df_mat.dropna(axis = 1, how = 'all').fillna(0)        # Create a gene matrix
        gene_matrix = df_mat.loc[[i for i in gene_list if i in df_mat.index], :].copy()
        # Remove genes with 0 LFC in PROP of samples
        gene_matrix = gene_matrix.loc[((gene_matrix != 0).mean(axis = 1)) > PROP, :]
        # Remove genes with NA in PROP of samples
        gene_matrix = gene_matrix.loc[gene_matrix.isna().mean(axis = 1) < PROP, :]
        gene_matrix = gene_matrix.loc[gene_matrix.median(axis = 1).sort_values(ascending = False).index, :]
        return gene_matrix, n_genes
    else:
        # Drop duplicates
        gene_df = gene_df.drop_duplicates(subset = ['gene', 'dataset'])        
        gene_df = gene_df.sort_values(by = ['log2FoldChange', 'dataset'], ascending = [True, True])

        return gene_df, dataset_df

def plot_gene_set_per_dataset(df, dataset_df, title = '', figsize = (6,7), x = 'log2FoldChange', y = 'cell_line', hue = False, dodge = False, palette = 'Oranges', savefig = '', alpha = .5, size = 2.5, xlab = 'log2FoldChange', legend = True, legend_title = 'Lombardi h-index', sort_by = 'lombardi_hindex', dataset_sort_by = 'up_or_down', linewidth = 1, width = .5, ascending = False, correlate = True, corr_col = 'oxphos_coordination_value', show_total = True, extra_x_cat = False, ylabel = 'Cell Line', relabel = True, mark_local = True):
    """
    Plot the log2FoldChange of a gene set per dataset
    """
    if dataset_sort_by == 'up_or_down':
        mean_up = round(dataset_df.up.mean(), 2)
        std_up = round(dataset_df.up.std(), 2)
        mean_down = round(dataset_df.down.mean(), 2)
        std_down = round(dataset_df.down.std(), 2)
        print(f'Mean up: {mean_up}+-{std_up}, mean down: {mean_down}+-{std_down}')
        dataset_sort_by = 'up' if mean_up > mean_down else 'down'
    if extra_x_cat:
        dataset_df = dataset_df.sort_values(by = [extra_x_cat, dataset_sort_by], ascending = [True, ascending])
    else:
        dataset_df = dataset_df.sort_values(by = dataset_sort_by, ascending = ascending)
    order = dataset_df[y].tolist()
    if extra_x_cat:
        _, axes = plt.subplots(1, 3, figsize = figsize, sharey = True, gridspec_kw={'width_ratios': [.45, 2, 1]})
        sns.pointplot(ax = axes[0], x = extra_x_cat, y = y, data = dataset_df, color = 'tab:red', alpha = .5, join = False, linewidth = 10, edgecolor = 'black', order = order)
        axes[0].set_ylabel(ylabel)  

        # Add line at 0.5 and 1
        axes[0].axvline(x = 0.5, linestyle = '--', color = 'red')
        axes[0].axvline(x = 1, linestyle = '--', color = 'orange') 
        # Change ticklabels to percentages
        axes[0].set_xticks([ 0.5, 1])
        axes[0].set_xticklabels([ '0.5%', '1%'], rotation = 45)
        axes[0].set_xlim([0, 1.1])
        ax = axes[1]
        ax2 = axes[2]
    else:
        _, axes = plt.subplots(1, 2, figsize = figsize, sharey = True, gridspec_kw={'width_ratios': [2, 1]})
        ax = axes[0]
        ax2 = axes[1]
    # Make the three barplots
    sns.barplot(y = y, x = 'total', data = dataset_df, ax = ax2, color = 'black', label = 'Non-significant', alpha = .5, fill=False, linewidth=1)
    sns.barplot(y = y, x = 'up+down', data = dataset_df, ax = ax2, color = 'tab:green', label = 'Upregulated')
    sns.barplot(y = y, x = 'down', data = dataset_df, ax = ax2, color = 'tab:red', label = 'Downregulated')
    # Add more 
    if hue:
        sns.boxplot(ax = ax, y = y, x = x, hue = hue, dodge = dodge, data = df, orient = 'h', palette = palette, width = width, order = order)
    else:
        sns.boxplot(ax = ax, y = y, x = x, data = df, orient = 'h', color = 'grey', linewidth = linewidth, width = width, order = order)
    # Add stripplot
    sns.stripplot(ax = ax, y = y, x = x, data = df, orient = 'h', color = 'black', alpha = alpha, size = size, order = order)
    # Set line at x=0
    ax.axvline(x = 0, linestyle = '-', color = 'red')

    # Set legend outside of plot
    if hue: ax.legend(title = hue.capitalize().replace('_' , ' '), bbox_to_anchor=(1.68, 0.83), loc='upper left', fontsize = 8)
    else: pass
    if legend: ax2.legend(title = '', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize = 8)
    # Set xlabel 
    if show_total:
        ax2.set_xlabel(f'N genes (total = {dataset_df["total"].max()})', fontsize = 8)
    else:
        ax2.set_xlabel(f'N genes', fontsize = 8)
    # Desine
    sns.despine()
    if extra_x_cat and relabel and not mark_local:
        axes[0].set_yticklabels([dataset_df['cell_line'].iloc[i] for i in range(len(dataset_df))], fontsize = 8)
    elif extra_x_cat and relabel and mark_local:
        axes[0].set_yticklabels([f"{dataset_df[dataset_df[y] == i].cell_line.iloc[0]}*" if 'local' in dataset_df[dataset_df[y] == i].dataset.iloc[0] else dataset_df[dataset_df[y] == i].cell_line.iloc[0] for i in order])    # X axis label 
    ax.set_xlabel(xlab)
    # Y axis label
    ax.set_ylabel('')
    ax2.set_ylabel('')
    # Set title
    if correlate:
        corr_value = stats.spearmanr(dataset_df[corr_col], dataset_df['mean_lfc'])
        ax.set_title(f'{title} R={round(corr_value[0], 1)}, P-value={round(corr_value[1], 3)}', fontsize = 8)
        g = sns.lmplot(x = corr_col, y = 'mean_lfc', data = dataset_df, height = 3, aspect = 1, scatter_kws={'alpha':0.5, 'color' : f'tab:green'}, line_kws={'color': f'tab:grey'})
        g.set_axis_labels(corr_col.capitalize().replace('_', ' '), 'log2 Fold Change')
        g.set_titles(title)
    else:
        ax.set_title(title)
    plt.tight_layout()
    if savefig != '':
        plt.savefig(os.path.join(PATH, 'figures', f'{savefig}.svg'), bbox_inches = 'tight')

def plot_mtcp(df, x, y, title, savefig = False, figsize = (3,3), palette = ['tab:green', 'tab:red'], strip_color = 'black', strip_size = 5, strip_jitter = False, strip_alpha = 1, test = "Mann-Whitney", hide_non_significant=False, hue = False):
    """
    """
    df = df.sort_values(x, ascending = False).copy()
    # Infer pairs based on x values
    treats = df[x].unique().tolist()
    pairs = [(treats[i], treats[j]) for i in range(len(treats)) for j in range(i+1, len(treats))]
    _, axes = plt.subplots(1, 1, figsize=figsize)
    sns.barplot(x = x, y = y, data = df, ax = axes,  palette=palette)
    # Add a stripplot
    sns.stripplot(x = x, y = y, data = df, ax = axes, color=strip_color, size=strip_size, jitter = strip_jitter, alpha = strip_alpha)
    # Set title
    axes.set_title(title)
    axes.set_xlabel('')
    axes.set_ylabel('Relative copy number')
    # Replace Hyp with Hypoxia and Norm with Normoxia
    sns.despine()
    annotate = Annotator(x = x, y = y, data = df, ax=axes, pairs = pairs,  verbose = 1, hide_non_significant=hide_non_significant)
    annotate.configure(text_format = 'star', test = test, hide_non_significant=hide_non_significant)
    annotate.apply_and_annotate()
    plt.tight_layout()
    if savefig:
        plt.savefig(os.path.join(PATH, 'figures', f'{savefig}.svg'), bbox_inches = 'tight')



def kl_divergence(mean_1, std_1, mean_2, std_2):
    """Calculates the KL divergence between two normal distributions.

    Args:
        p: A tuple (mean_p, std_dev_p) representing the first normal distribution.
        q: A tuple (mean_q, std_dev_q) representing the second normal distribution.

    Returns:
        The KL divergence between the two distributions.
    """
    # Calculate KL divergence
    kl_div = 0.5 * (np.log(std_2**2 / std_1**2) + (std_1**2 + (mean_1 - mean_2)**2) / std_2**2 - 1)
    print("KL Divergence:", round(kl_div, 2))
    return kl_div

def make_per_dataset_df(df, dataset_col = 'dataset', gene_col = 'gene'):
     """
     Recieve a dataframe of a subset of genes and return a dataframe with the number of up, down and nonsignificant genes per dataset
     """
     dataset_dict = {dataset_col : [], 'cell_line' : [], 'up' : [], 'down' : [], 'nonsign' : [], 'total' : [], 'mean_lfc' : [], 'oxphos_coordination_value' : []}
     for dataset in df[dataset_col].unique():
        cur = df[df[dataset_col] == dataset].copy()
        n_genes = len(cur[gene_col].unique())
        up = round((len(cur[(cur['log2FoldChange'] > 0) & (cur['padj'] < 0.05)]))/ n_genes * 100, 2)
        down = round((len(cur[(cur['log2FoldChange'] < 0) & (cur['padj'] < 0.05)])) / n_genes * 100, 2)
        dataset_dict[dataset_col].append(dataset)
        dataset_dict['cell_line'].append(cur.cell_line.iloc[0])
        dataset_dict['up'].append(up)
        dataset_dict['down'].append(down)
        dataset_dict['nonsign'].append(100 - up - down)
        dataset_dict['total'].append(n_genes)
        dataset_dict['mean_lfc'].append(cur.loc[: ,'log2FoldChange'].median())
        if 'oxphos_coordination_value' in cur.columns:
            dataset_dict['oxphos_coordination_value'].append(cur['oxphos_coordination_value'].iloc[0])
        else:
            dataset_dict['oxphos_coordination_value'].append(np.nan)
     dataset_df = pd.DataFrame(dataset_dict)
     dataset_df['up+down']= dataset_df['up'] + dataset_df['down']
     dataset_df['max_pct'] = 100
     return dataset_df

def make_coord_plots(df, title, save_name, dataset_df_nuc = pd.DataFrame(), dataset_df_mt = pd.DataFrame(), strip_alpha = .05, kind = 'box', dodge = True, s = 3, hue = 'Genome', y = 'dataset_short', x = 'log2FoldChange', figsize = (5, 6), edgecolor = 'grey', linewidth = 1, ylabel = 'Dataset', xlabel = 'Log2 Fold Change', dataset_sort_by = 'up_or_down', extra_x_cat = False, custom_order = False, barplot_x = 'Percentage of genes', mark_local = True):
    """
    Make a plot of the coordinated and uncoordinated genes
    """
    if len(dataset_df_nuc) > 0:
        dataset_df_nuc['Genome'] = 'NUC'
        dataset_df_mt['Genome'] = 'MT'
        dataset_df = pd.concat([dataset_df_nuc, dataset_df_mt])
        dataset_df = dataset_df[dataset_df[y].isin(df[y].unique())]
        if extra_x_cat:
            dataset_df_gouped = dataset_df.groupby([y]).agg({'up' : 'mean', 'down' : 'mean', 'mean_lfc' : 'mean', 'cell_line' : 'first', extra_x_cat : 'first'}).reset_index()
        else:
            dataset_df_gouped = dataset_df.groupby([y]).agg({'up' : 'mean', 'down' : 'mean', 'mean_lfc' : 'mean', 'cell_line' : 'first'}).reset_index()
        # Sort dataset df by the order of df
        if dataset_sort_by == 'up_or_down':
            mean_up = np.mean([round(dataset_df_nuc.up.mean()), round(dataset_df_mt.up.mean())])
            std_up = round(dataset_df_nuc.up.std())
            mean_down = np.mean([round(dataset_df_nuc.down.mean()), round(dataset_df_mt.down.mean())])
            std_down = round(dataset_df_nuc.down.std())
            print(f'Mean up: {mean_up} +- {std_up}\nMean down: {mean_down} +- {std_down}')
            dataset_sort_by = 'up' if mean_up > mean_down else 'down'
        if extra_x_cat:
            order = dataset_df_gouped.sort_values([extra_x_cat, dataset_sort_by], ascending = [True, False])[y].tolist()
            _, axes = plt.subplots(1, 3, figsize = figsize, sharey = True, gridspec_kw={'width_ratios': [.45, 2, 1]})
            sns.pointplot(ax = axes[0], x = extra_x_cat, y = y, data = dataset_df_nuc, color = 'tab:red', join = False, linewidth = 10, order = order, markers='o', markersize=10)
            axes[0].set_ylabel(ylabel)  
            # Add line at 0.5 and 1
            axes[0].axvline(x = 0.5, linestyle = '--', color = 'red')
            axes[0].axvline(x = 1, linestyle = '--', color = 'orange') 
            # Change ticklabels to percentages
            axes[0].set_xticks([0.5, 1])
            axes[0].set_xticklabels(['0.5%', '1%'], rotation = 45)
            axes[0].set_xlim([0, 1.1])
            ax = axes[1]
            ax2 = axes[2]
        else:
            order = dataset_df_gouped.sort_values(dataset_sort_by, ascending = False)[y].tolist()
            _, axes = plt.subplots(1, 2, figsize = figsize, sharey = True, gridspec_kw={'width_ratios': [2, 1]})
            ax = axes[0]
            ax2 = axes[1]
        if custom_order:
            order = custom_order
        sns.barplot(ax = ax2, x = 'max_pct', y = y, data = dataset_df,  dodge = True, hue = 'Genome'
        ,palette = ['grey'], linewidth = 0.5, edgecolor = 'black',  hue_order = ['NUC', 'MT'], alpha = 0.5, fill = False, order = order)
        sns.barplot(ax = ax2, x = 'up+down', y = y, data = dataset_df,  dodge = True, hue = 'Genome'
        ,palette = ['tab:green'], linewidth = 0.25, edgecolor = 'black', hue_order = ['NUC', 'MT'], order = order)
        sns.barplot(ax = ax2, x = 'down', y = y, data = dataset_df,  dodge = True,hue = 'Genome'
        , palette = ['tab:red'], linewidth = 0.25, edgecolor = 'black', hue_order = ['NUC', 'MT'], order = order)
        ax2.set_xlabel(barplot_x)
        ax2.set_ylabel('')
        # Drop legend
        ax2.get_legend().remove()
        # Add xlabel at 0, 25, 50, 75 and 100
        ax2.set_xticks([0, 25, 50, 75, 100])
        # At x=100, add text saying NUC and MT
        ax2.text(101, -0.2, 'NUC', verticalalignment = 'center', horizontalalignment = 'left', fontsize = 8)
        ax2.text(101, 0.25, 'MT', verticalalignment = 'center', horizontalalignment = 'left', fontsize = 8)
    else:
        _, ax = plt.subplots(figsize = figsize)
        order = df[y].tolist()
    if kind == 'box':
        sns.boxplot(ax = ax, data = df, hue = hue, x = x, y = y, dodge = dodge,  palette = 'Set2', hue_order = ['NUC', 'MT'], order = order)
        # Remove boxplot legend
        # Add stripplot with low alpha
        sns.stripplot(ax = ax,  data = df,x = x, y = y, hue = hue, dodge = dodge, palette = 'Set2', alpha = strip_alpha, size = s, hue_order = ['NUC', 'MT'], linewidth = .5, edgecolor = 'black', order = order)
        ax.get_legend().remove()

    else:
        sns.boxplot(ax = ax, x = x, y = y,  data = df, palette = ['grey'], order = order)
        # Remove boxplot legend
        sns.stripplot(ax = ax, data = df[df.Genome == 'NUC'], hue = hue, x = x, y = y, dodge = dodge,  palette = 'Set2', alpha = strip_alpha, s = s, hue_order = ['NUC', 'MT'], linewidth = .5, edgecolor = 'black', order = order)
        # Make MT points large
        sns.stripplot(ax = ax, data = df[df.Genome == 'MT'], hue = hue, x = x, y = y, dodge = dodge,  palette = 'Set2', alpha = strip_alpha, s = s*2, hue_order = ['NUC', 'MT'], edgecolor = edgecolor, linewidth=linewidth, order = order) 
        ax.get_legend().remove()
    if extra_x_cat:
        ax.set_ylabel('')
        ax.set_xlabel(xlabel)
        ax.set_title(title)
        # Chance the yticklabels to the values of 'cell_line'
        if not mark_local:
            axes[0].set_yticklabels([dataset_df_nuc[dataset_df_nuc[y] == i].cell_line.iloc[0] for i in order])
        else: 
            axes[0].set_yticklabels([f"{dataset_df_nuc[dataset_df_nuc[y] == i].cell_line.iloc[0]}*" if 'local' in dataset_df_nuc[dataset_df_nuc[y] == i].dataset.iloc[0] else dataset_df_nuc[dataset_df_nuc[y] == i].cell_line.iloc[0] for i in order])
    else:
        ax.set(ylabel = ylabel, xlabel = xlabel, title = title)
    # Add a line at x = 0
    ax.axvline(x = 0, color = 'k', linestyle = '--')
    # Move legend out of the plot
    # Set x and y axis labels
    sns.despine()
    plt.tight_layout()

    #Save figure to 'figure_articles' folder
    plt.savefig(os.path.join(PATH, 'figures', f'{save_name}_coordinated_uncoordinated_log2foldchange.svg'), bbox_inches = 'tight')

def plot_gene_clustermap(mat, col_annot = None, col_annot_cols = None, row_annot = None, row_annot_cols = None, col_annot_dicts = [], cmap = 'RdBu_r', figsize = (5.5, 7.5), col_cluster = True, row_cluster = True, xticklabels = False, yticklabels = 'auto', cbar_kws = {'label' : 'LFC'}, dendrogram_ratio = (.1, .1), cbar_pos = (.9, .9, .03, .1), vmin = -2.5, vmax = 2.5,  center = 0, rasterized = True, mask = False, xlabel = 'Dataset', ylabel = 'Gene', savefig = False):
    """
    """
    if row_annot_cols != None and col_annot_cols != None:
        row_annot = row_annot[row_annot_cols]
        col_annot = col_annot[col_annot_cols]
        cm = sns.clustermap(mat, cmap = cmap, figsize = figsize, col_cluster = col_cluster, row_cluster = row_cluster, xticklabels = xticklabels, yticklabels = yticklabels, cbar_kws = cbar_kws, dendrogram_ratio = dendrogram_ratio, cbar_pos = cbar_pos, vmin = vmin, vmax = vmax, center = center, rasterized = rasterized, mask = mask, row_colors = row_annot, col_colors = col_annot)
    elif row_annot_cols != None and col_annot_cols == None:
        row_annot = row_annot[row_annot_cols]
        cm = sns.clustermap(mat, cmap = cmap, figsize = figsize, col_cluster = col_cluster, row_cluster = row_cluster, xticklabels = xticklabels, yticklabels = yticklabels, cbar_kws = cbar_kws, dendrogram_ratio = dendrogram_ratio, cbar_pos = cbar_pos, vmin = vmin, vmax = vmax, center = center, rasterized = rasterized, mask = mask, row_colors = row_annot)
    elif row_annot_cols == None and col_annot_cols != None:
        col_annot = col_annot[col_annot_cols]
        cm = sns.clustermap(mat, cmap = cmap, figsize = figsize, col_cluster = col_cluster, row_cluster = row_cluster, xticklabels = xticklabels, yticklabels = yticklabels, cbar_kws = cbar_kws, dendrogram_ratio = dendrogram_ratio, cbar_pos = cbar_pos, vmin = vmin, vmax = vmax, center = center, rasterized = rasterized, mask = mask, col_colors = col_annot)
    else:
        cm = sns.clustermap(mat, cmap = cmap, figsize = figsize, col_cluster = col_cluster, row_cluster = row_cluster, xticklabels = xticklabels, yticklabels = yticklabels, cbar_kws = cbar_kws, dendrogram_ratio = dendrogram_ratio, cbar_pos = cbar_pos, vmin = vmin, vmax = vmax, center = center, rasterized = rasterized, mask = mask)

    cm.ax_heatmap.set_xlabel(xlabel)
    cm.ax_heatmap.set_ylabel(ylabel)
    legends = []
    for i, v in enumerate(col_annot_dicts):
        handles = [Patch(color = color, label = str(label) + '%' if (type(label) == int) or (type(label) == float) else label) for label, color in v.items()]
        legends.append(plt.legend(handles = handles, title = col_annot_cols[i], loc = 'upper left', bbox_to_anchor = (5, i), fontsize = 8))
        #plt.gca().add_artist(legend)
    
    # Add all legends
    for j, legend in enumerate(legends):
        if j < i:
            plt.gca().add_artist(legend)
    plt.setp(cm.ax_heatmap.yaxis.get_majorticklines(), visible=False)
    plt.setp(cm.ax_heatmap.yaxis.get_majorticklabels(), rotation=0, fontsize = 8)

    if savefig:
        plt.savefig(os.path.join(PATH, 'figures', f'{savefig}'), bbox_inches = 'tight')



PATH = os.getcwd()
reload(fr)
reload(dftc)
reload(consts)

def Which_tRNA(name, verbosity = 1):
    """ This code recieves a gene name, tries to match it with common tRNA motifs, and then with any matching values in the replacement dict, if nothing matches, returns None
    which is later removed"""
    name = name.replace('*', '')
    if name in consts.REPLACEMENT_DICT.keys(): return name 
    if 'trn' in name: return name
    c=0
    name=str(name)
    if 'transfer' in name:
        name = name.replace('transfer ','t')
    codon = re.search(r'\(\w{3}\)',name) # Grab codon if it exists
    if codon: codon = codon.group(0)
    else: codon=''
    name = re.sub(pattern=r'\(\w{3}\)',repl = '',string = name)
    if name in consts.TRNA_DICT.keys():  # if the tRNA is in tRNA-X format, replace with my format and return
        name = consts.TRNA_DICT[name]
        return name+codon

    #Following lines try to match with each possible tRNA.
    if re.match(r't[r,R]\D{1,2}(H|His)',name):
        name='tRNA-His'
        
    if re.match(r't[r,R]\D{1,2}(K|Lys)',name):
        name='tRNA-Lys'
        
    if re.match(r't[r,R]\D{1,2}(R|Arg)',name):
        name='tRNA-Arg'
        
    if re.match(r't[r,R]\D{1,2}(D|Asp)',name):
        name='tRNA-Asp'
        
    if re.match(r't[r,R]\D{1,2}(E|Glu)',name):
        name='tRNA-Glu'
        
    if re.match(r't[r,R]\D{1,2}S',name):
        name='tRNA-Ser'
        
    if re.match(r't[r,R]\D{1,2}T',name):
        name='tRNA-Thr'
        
    if re.match(r't[r,R]\D{1,2}(N|Asn)',name):
        name='tRNA-Asn'
        
    if re.match(r't[r,R]\D{1,2}(Q|Gln)',name):
        name='tRNA-Gln'
        
    if re.match(r't[r,R]\D{1,2}V',name):
        name='tRNA-Val'
        
    if re.match(r't[r,R]\D{1,2}L',name):
        name='tRNA-Leu'
        
    if re.match(r't[r,R]\D{1,2}I',name):
        name='tRNA-Ile'
        
    if re.match(r't[r,R]\D{1,2}M',name):
        name='tRNA-Met'
        
    if re.match(r't[r,R]\D{1,2}(F|Phe)',name):
        name='tRNA-Phe'
        
    if re.match(r't[r,R]\D{1,2}(Y|Tyr)',name):
        name='tRNA-Tyr'
        
    if re.match(r't[r,R]\D{1,2}(W|Trp)',name):
        name='tRNA-Trp'
        
    if re.match(r't[r,R]\D{1,2}P',name):
        name='tRNA-Pro'
        
    if re.match(r't[r,R]\D{1,2}G',name):
        name='tRNA-Gly'
        
    if re.match(r't[r,R]\D{1,2}C',name):
        name='tRNA-Cys'
    
    if re.match(r't[r,R]\D{1,2}A',name):
        name='tRNA-Ala'
        
    for k,v in consts.REPLACEMENT_DICT.items(): # if not tRNA, this loop matches according to replacement dict
        if name in v:
            name=k
            return name
        if c==len(consts.REPLACEMENT_DICT)-1:
            name=None
            return name
        c=+1
    try:
        if name in consts.TRNA_DICT.keys(): # if matched with any of the if's above (for tRNAs), replace with my annotation accordingly.
            name = consts.TRNA_DICT[name]
            return name+codon
    except KeyError:
        pass
    if verbosity > 0:
        print(name)
    if 'RNA' in name or 'rna' in name:
        return None
    elif 'orf' in name or 'ORF' in name:
        return 'ORFX'
    else:
        if verbosity > 0:
            print(f"Could not replace {name} - returning it")
        return name

def retrieve_gb(ID) -> str:
    """
    Retrieve GenBank record from NCBI given an ID.

    Parameters
    ----------
    ID : str
        The ID of the record to retrieve
    
    Returns
    -------
    filename : str
        The path to the record retrieved from NCBI
    """
    if not os.path.isdir(os.path.join(PATH, 'genebank.DB')):
        os.mkdir(os.path.join(PATH, 'genebank.DB'))
    filename = os.path.join(PATH, 'genebank.DB', ID + '.gbk')
    if not os.path.isfile(filename):
        print(f'Downloading {ID}\n')
        net_handle = Entrez.efetch(db ='nucleotide', id = ID, rettype = 'gb', retmode = 'text')
        out_handle = open(filename, 'w')
        out_handle.write(net_handle.read())
        out_handle.close()
        net_handle.close()
        print(f'Saved {ID}\n')
    return filename

def deseq(sample) -> pd.DataFrame:
    """
    Perform DESeq normalization on a sample.

    Parameters
    ----------
    sample : pd.DataFrame   
        The sample to be normalized
    
    Returns
    -------
    sample : pd.DataFrame
        The normalized sample
    """
    deseq_log = np.log(sample)
    deseq_log = deseq_log.replace([np.inf, -np.inf], np.nan).dropna(how = 'all')
    deseq_log['row_mean'] = deseq_log.mean(axis = 1)
    deseq_log_ratio = deseq_log.loc[:, deseq_log.columns != 'row_mean'].sub(deseq_log.row_mean, axis = 'rows')
    deseq_log_ratio_median = np.exp(deseq_log_ratio.median(axis = 0))
    sample = sample.divide(deseq_log_ratio_median)
    return sample

def deseq_from_long(sample, gene_col, count_col, sample_col) -> pd.DataFrame:
    """
    Convert long format to wide format, perform DESeq normalization, and return to long format.

    Parameters
    ----------
    sample : pd.DataFrame
        The long-format dataframe
    gene_col : str
        The gene name column
    count_col : str
        The raw count column
    sample_col : str
        

    Returns
    -------
    sample : pd.DataFrame
        The DESeq-normalized dataframe

    """
    sample = sample.pivot_table(values = count_col, index = gene_col, columns = sample_col)
    sample = deseq(sample)
    sample = sample.reset_index().melt(id_vars = gene_col, value_name = 'junc_deseq')
    return sample

def mtdna_region(pos, window, total, left, inclusive = True) -> str:
    """
    Designed for circular DNA, return a list of positions (INDEX 1 BASED) to the left or right side of pos

    Parameters
    ----------
    pos : int
        The current position to return a window around
    window : int
        The size of the window
    total : int
        The total size of the DNA
    left : bool
        True if the window should be to the left of the
    inclusive :
        (Default value = True)

    Returns
    -------
    positions : list
        A list of positions (INDEX 1 BASED) to the left or right side of pos
    """

    if type(left) != bool: raise TypeError(f'Parameter left must be either True (left side window) or False (right side window! Given {left} instead')
    if total < window or total < pos:
        raise ValueError(f'The total size of the DNA must be smaller than both the window and the position!\nParameters given:\nTotal = {total}\nPosition = {pos}\nWindow = {window}')
    
    positions = []
    if left:
        if pos - window < 1:
            positions += list(range(total - abs(window - pos) + (1 if inclusive else 0), total + 1))
            positions += list(range(1, pos + (1 if inclusive else 0)))
        else:
            positions += list(range(pos - window + (1 if inclusive else 0), pos + (1 if inclusive else 0)))
    else: #right
        if pos + window > total:
            positions += list(range(1, (pos + window) - total + (0 if inclusive else 1)))
            positions += list(range(pos + (0 if inclusive else 1), total + 1))
        else:
            positions += list(range(pos + (0 if inclusive else 1), pos + window + 1))
    return positions

def mtdna_distance(y, x, mt_len, left_size):
    """
    """
    if x > y:
        return -min(x - y, mt_len - x + y)
    elif abs(mt_len - y) < left_size:
        return -min(y - x, mt_len - y + x)
    else:
        return min(y - x, mt_len - y + x)

def plotly_sample(sample_path, plot_col = 'coverage', window = 100, peaks = False):
    """
    Create a plotly graph of a single sample expression, graphs both strands with negative values for light strand and positive values for the heavy strand.

    Parameters
    ----------
    sample_path :
        
    plot_col :
        (Default value = 'coverage')

    window :
        (Default value = 100)
    peaks :
        (Default value = False)

    Returns
    -------

    """
    sample = pd.read_csv(sample_path, index_col = 0)
    sample_name = os.path.split(sample_path)[-1].replace('.csv','')
    pos_col = 'pos_' + plot_col
    neg_col = 'neg_' + plot_col
    sample[[pos_col, neg_col]] = sample[[pos_col, neg_col]].fillna(0).rolling(window = window, min_periods = 1).mean()

    sub_sample = sample[['Position', pos_col, neg_col]]
    sub_sample = sub_sample.rename({pos_col : 'Heavy strand', neg_col : 'Light strand'}, axis = 1)
    sub_sample['Light strand'] = sub_sample['Light strand'] * -1
    sub_sample = sub_sample.melt(id_vars = 'Position', value_vars = ['Heavy strand', 'Light strand'], var_name = 'Strand', value_name = 'Coverage')
    fig = px.line(sub_sample, x = 'Position', y = 'Coverage', color = 'Strand', title = f'Expression profile of {sample_name}')
    if type(peaks) == pd.DataFrame:
        for i, peak in peaks.iterrows():
            fig.add_vline(
                x = peak.Position, \
                line_color = 'green' if peak.Type == 'TIS' else 'red',
                line_dash = 'dash' if peak.Strand == 'Heavy' else 'dot',
                annotation_text = peak.Strand)
    
    return fig

def ratio_score(i, df, strand, up_window = 250, down_window = 50, normalized = False) -> float:
    """
    Calculate the ratio of downstream coverage to downstream + upstream coverage, with downstream and upstream defined as right and left or left and right for the heavy strand and light strand respectively.

    Parameters
    ----------
    i : int
        The current position
    df : pd.DataFrame
        The dataframe containing the coverage data
    strand : str
        The strand to calculate the ratio for
    up_window : int
        The upstream window size
    down_window : int
        The downstream window size
    normalized : bool
        (Default value = False) If True, the ratio will be normalized by the mean of the upstream and downstream windows
    
    Returns
    -------
    float
        The ratio of downstream coverage to downstream + upstream coverage
    

    """
    strand_name = 'pos' if strand else 'neg'
    cov_col = 'RPM' if normalized else 'coverage' 
    total = df.Position.max()
    if strand:
        down_window_pos = mtdna_region(i, down_window, total, False)
        down_mean_cov = df.loc[df.Position.isin(down_window_pos), f'{strand_name}_{cov_col}'].mean() + 1
        
        up_window_pos = mtdna_region(i, up_window, total, True)
        up_mean_cov = df.loc[df.Position.isin(up_window_pos), f'{strand_name}_{cov_col}'].mean() + 1
    else:
        down_window_pos = mtdna_region(i, down_window, total, True)
        down_mean_cov = df.loc[df.Position.isin(down_window_pos), f'{strand_name}_{cov_col}'].mean() + 1
        
        up_window_pos = mtdna_region(i, up_window, total, False)
        up_mean_cov = df.loc[df.Position.isin(up_window_pos), f'{strand_name}_{cov_col}'].mean() + 1
    
    # Return the ratio of downstream coverage to downstream + upstream coverages, this ratio is supposed to be low for TERM and high for TIS
    return down_mean_cov/(up_mean_cov + down_mean_cov)

def confidence_score(i, df, type, strand, normalized = True) -> float:
    """
    Defined as the inverse of downstream and upstream ratio for TERM sites and the downstream and upstream ratio for TIS sites. (TIS must have large ratio_scores and TERM must have low ratio scores.

    Parameters
    ----------
    i : int
        The current position
    df : pd.DataFrame
        The dataframe containing the coverage data
    type : str
        The type of site to calculate the confidence score for
    strand : str
        The strand to calculate the ratio for
    normalized : bool
        (Default value = False) If True, the ratio will be normalized by the mean of the upstream and downstream windows
    
    Returns
    -------
    float
        The confidence score of the site
    
    """
    ratio_sc = ratio_score(i, df, strand, normalized = normalized)
    if type == 'TERM':
        confidence_sc = 1 - ratio_sc
    elif type == 'TIS':
        confidence_sc = ratio_sc
    return confidence_sc

def dist_from_source(i, total_len) -> int:
    """
    Calculate the mtDNA positions in terms of distance relative to 0 position (negative for left side and positive for right side).

    Parameters
    ----------
    i : int
        The current position
    total_len : int
        The total length of the mtDNA region
    
    Returns
    -------
    int
        The distance from the source
    """
    if i >= total_len/2:
        return ((total_len - i) + 1) * -1
    elif i < total_len/2:
        return i

def z_score(n, mean, std) -> float:
    """
    Compute Z-score.

    Parameters
    ----------
    n : int 
        The number to compute the Z-score for
    mean : float
        The mean of the distribution
    std : float
        The standard deviation of the distribution
    
    Returns
    -------
    float
        The Z-score
    
    References
    ----------
    https://en.wikipedia.org/wiki/Standard_score
    """
    try: return (n - mean) / std
    except ZeroDivisionError: return 0

def scale_min_max(n, mini, maxi, multiply = 1) -> float:
    """
    Compute scaled min_max value

    Parameters
    ----------
    n : int 
        The number to compute the scaled value for
    mini : int
        The minimum value of the scaled range
    maxi : int
        The maximum value of the scaled range
    
    Returns
    -------
    float
        The scaled value
    
    References
    ----------
    https://en.wikipedia.org/wiki/Normalization_(statistics)
    """
    try: return ((n - mini) / (maxi - mini)) * multiply
    except ZeroDivisionError: return 0

def get_medians(df, sep_col, value_col) -> pd.DataFrame:
    """
    Grab the median of value_col grouped by sep_col

    Parameters
    ----------
    df : pd.DataFrame
        The dataframe containing the coverage data
    sep_col : str
        The column to group by
    value_col : str
        The column to compute the median for
    
    Returns
    -------
    pd.Series
        The median of value_col grouped by sep_col
    """
    mean_list = []
    for i in df[sep_col].unique():
        mean_list.append(df.loc[df[sep_col] == i, value_col].median())
    return mean_list

def num_sim(n1 : int, n2 : int) -> int:
    """
    calculates a similarity score between 2 numbers

    Parameters
    ----------
    n1 : int
        The first number
    n2 : int
        The second number
    
    Returns
    -------
    int
        The similarity score
    """
    return 1 - abs(n1 - n2) / (n1 + n2)

def get_org_name_from_refseq(ID):
    """
    Get the organism name from a refseq ID

    Parameters
    ----------
    ID : str
        The refseq ID
    
    Returns
    -------
    str
        The organism name
    """
    return '_'.join(SeqIO.read(retrieve_gb(ID), 'gb').features[0].qualifiers.get('organism')[0].replace(' ', '_').split('_')[0:2])

def get_org_filtered_expr(org, plotlist = ['RPM'], hline = 'mean', filtered = True, window = 50, tis_term_df = '', dataset_title = False) -> pd.DataFrame:
    """
    Iterate over each file in annotated_pileup folder, create a gigantic dataframe of all files, and plot
    the means of values in plotlist into a coverage_graph plot.

    Parameters
    ----------
    org :
        The organism to plot     
    plotlist :
        (Default value = ['RPM']) The list of columns to plot
    hline :
        (Default value = 'mean') The value to plot as a horizontal line
    filtered :
        (Default value = True) If True, the dataframe will be filtered by the mean of the values in plotlist
    window :
        (Default value = 50) The window size to use for the rolling mean
    tis_term_df :
        (Default value = '') The dataframe containing the TIS and TERM sites
    dataset_title :
        (Default value = False) If True, the title of the plot will be the name of the dataset
    """
    title = ''
    org_initials = ''.join([i[0] for i in org.replace('_',' ').split(' ')]).upper()
    all_files = glob.glob(os.path.join('data', 'annotated_pileup', f"*{org_initials}.csv"))
    if all_files == []:
        return None
    li = []
    c=0
    real_id = ''
    for filename in all_files:
        if org_initials not in filename: continue
        #Count organisms
        try: df = pd.read_csv(filename, index_col=0, header=0)
        except pd.EmptyDataError: continue
        try: id = df.Chromosome.dropna().iloc[0]
        except IndexError:
            continue
        if real_id == '':
            cur_org = '_'.join(SeqIO.read(retrieve_gb(id), 'gb').features[0].qualifiers.get('organism')[0].replace(' ', '_').split('_')[0:2])
            if cur_org == org:
                real_id = id
            else:
                continue
        else:
            if real_id != id:
                #print(f'Wrong ID {id}')
                continue
        df['org'] = org
        li.append(df)
        c+=1
    if li == []:
        print('None')
        return None
    #Combine all sample junction dfs to a single one
    annotated_df = pd.concat(li, axis=0, ignore_index=True)
    agg_dict = {'coverage':'median', 'RPM':'median','RPM':'std', 'z':'median',
                'ends_ratio':'median', 'Gene':'first', 'Strand':'first'}
    for i in annotated_df.dataset.unique():
        cur_df = annotated_df.loc[(annotated_df.dataset == i) & (annotated_df.org == org), :]
        cur_df = cur_df.groupby('Position').agg(agg_dict).reset_index().sort_values(by = 'Position')
        if len(li) == 1:
            cur_df = annotated_df
        if filtered: cur_df = fr.main(sample = cur_df, filtered = False, org = org.replace('_', ' '), flank = window,
                                      direction = 'downstream')

        if dataset_title:
            title = i                              
        dftc.coverage_graph(org.replace('_', ' '), cur_df, None, plotlist = plotlist, hline = hline, title_org = True, tis_term_df=tis_term_df, custom_title=title)

def falloff_score(row) -> float:
    """
    Compute the falloff score for a row

    Parameters
    ----------
    row : pd.Series
        The row to compute the falloff score for
    
    Returns
    -------
    float
        The falloff score
    """
    st1 = row['left_strand']
    st2 = row['right_strand']
    left_exp = row['left_z']
    right_exp = row['right_z']
    junc_exp = row['junc_tpm_z']
    if (st1 == True and st2 == True) or (st1 == True and st2 == False):
        return (left_exp - junc_exp)
    if (st1 == False and st2 == False) or (st1 == False and st2 == True):
        return (right_exp - junc_exp)

def junc_type(row) -> str:
    """
    Compute the junction type for a row

    Parameters
    ----------
    row : pd.Series
        The row to compute the junction type for    
    
    Returns
    -------
    str
        The junction type
    """
    st1 = row['left_strand']
    st2 = row['right_strand']

    if st1 == True and st2 == True:
        return 'A' # Both sorrounding genes are in the Heavy strand
    elif st1 == False and st2 == False:
        return 'B' # Both sorrounding genes are in the Light strand
    elif st1 == True and st2 == False:
        return 'C' # The left gene is in the Heavy strand and the right gene is in the Light strand (head to head)
    elif st1 == False and st2 == True:
        return 'D' # The left gene is in the Light strand and the right gene is in the Heavy strand (tail to tail)
    else:
        print('Wrong mode! choose either type or falloff!\n')

def custom_boxplot(test_type = 'Mann-Whitney', loc = 'inside', box_pairs = [('DSJ','SSJ')],
                   t_format = 'star', xlabel = 'Strand switched', ylabel = 'log(expression)', savefig = False, style = 'default', despine = True, **kwargs):
    """
    Recieve a FacetPlot object, create a boxplot with **kwargs and use add_stat_annotation to perform a statistical test.

    Parameters
    ----------
    test_type :
        (Default value = 'Mann-Whitney') The statistical test to perform
    loc :
        (Default value = 'inside') The location of the annotation
    box_pairs :
        (Default value = [('DSJ') ('SSJ')]) The list of box pairs to perform the statistical test on
    'SSJ')] :
        
    t_format :
        (Default value = 'star') The format of the annotation
    xlabel :
        (Default value = 'Strand switched') The xlabel of the boxplot
    ylabel :
        (Default value = 'log(expression)') The ylabel of the boxplot
    **kwargs : 
        The kwargs to pass to FacetGrid.map_dataframe
    """
    if 'DSJ' not in kwargs['data']['strand_switch'].unique(): return 
    plt.style.use(style)
    _, ax = plt.subplots(figsize = (4,4))
    sns.boxplot(ax = ax, **kwargs)
    ax.set(xlabel = xlabel, ylabel = ylabel, title = kwargs['data']['org'].iloc[0].replace('_', ' '))
    add_stat_annotation(
        ax, data=kwargs['data'], x=kwargs['x'], y=kwargs['y'],
        box_pairs=box_pairs,
        test = test_type, loc = loc,
        text_format = t_format,
        verbose = 2
        )
    plt.tight_layout()
    if despine:
        sns.despine(ax = ax, offset = 10, trim = False)
    if savefig:
        plt.savefig(os.path.join(PATH, 'figures', f'{kwargs["data"]["org"].iloc[0].replace("_", " ")}_{kwargs["data"]["dataset"].iloc[0]}.svg'), dpi = 300)
    
def skree_plot(pca) -> None:
    """
    Recieve a PCA object, create a skree plot

    Parameters
    ----------
    pca : sklearn.decomposition.PCA
        The PCA object to plot
    
    """
    features = range(pca.n_components_)
    plt.plot(features, pca.explained_variance_ratio_ * 100, color = 'black', linestyle = '--', marker = 'o')
    plt.xlabel('PCA Features')
    plt.ylabel('Variance %')
    plt.xticks(features)
    plt.tight_layout()
    plt.show()

def elbow_plot(pca_reduced_df):
    """
    Recieve a dataframe of all PCA components - create elbow plot

    Parameters
    ----------
    pca_reduced_df : pd.DataFrame
        The dataframe of all PCA components
    """
    ks = range(1, 10)
    inertias = []
    for k in ks:
        model = KMeans(n_clusters = k)
        model.fit(pca_reduced_df)
        inertias.append(model.inertia_)
    plt.plot(ks, inertias, '-o', color = 'black')
    plt.xlabel('N clusters (k)')
    plt.ylabel('Inertia')
    plt.xticks(ks)
    plt.tight_layout()
    plt.show()

def sample_loader(folder, mode = 'random', agg = False):
    """
    Recieve a folder, load all samples in the folder

    Parameters
    ----------  
    folder : str
        The folder to load samples from
    
    Returns
    -------
    sample_path : str
        The path to the sample
    sample : pd.DataFrame
        The sample dataframe
    sample_name : str
        The name of the sample
    """
    if mode == 'random':
        sample_path = os.path.join(PATH, 'proseq', 'data', folder, random.choice([i for i in os.listdir(os.path.join(PATH, 'proseq', 'data', folder)) if os.path.split(i)[-1].replace(".csv","") if i.endswith('.csv')]))
        sample = pd.read_csv(sample_path, index_col = 0)
        sample_name = os.path.split(sample_path)[-1].replace(".csv","")
        print(f'The choice is {sample_name}')
        return sample_path, sample, sample_name
    elif mode == 'all':
        samples = []
        sample_path = os.path.join(PATH, 'proseq', 'data', folder)
        for i in sorted(os.listdir(sample_path)):
            if i.endswith('.csv'):
                sample = pd.read_csv(os.path.join(sample_path, i), index_col = 0)
                sample['ID'] = i.replace(".csv","")
                samples.append(sample)
        if agg:
            samples = pd.concat(samples)
            samples = samples.groupby('Position').median().reset_index()
        sample_name = folder
        return sample_path, samples, sample_name

def metadata_loader(folder):
    """
    Recieve a folder, load all metadata in the folder
    """
    metadata = pd.read_csv(os.path.join(PATH, 'proseq', 'data', folder, f'{folder}.tsv'), sep='\t')
    return metadata

def peaks_loader(name):
    """
    Recieve a name, load all peaks in the folder

    Parameters
    ----------
    name : str
        The name of the peaks to load
    
    Returns
    -------
    peaks : pd.DataFrame
        The peaks dataframe
    
    Example
    -------
    >>> peaks_loader('DSJ')

    """
    peaks_path = os.path.join(PATH, 'proseq', 'data',name + '_refined.csv')
    try:
        peaks = pd.read_csv(peaks_path)
        return peaks
    except FileNotFoundError:
        raise FileNotFoundError(f'No peaks for this study name! {name}')


def add_label_band(ax, top, bottom, label, *, spine_pos=-0.05, tip_pos=-0.02, orientation = 'vertical'):
    """Helper function to add bracket around y-tick labels.

    Parameters
    ----------
    ax : matplotlib.Axes
        The axes to add the bracket to
    top, bottom :
        The positions in *data* space to bracket on the y-axis
    label : str
        The label to add to the bracket
    spine_pos, tip_pos :
        The position in *axes fraction* of the spine and tips of the bracket.
        These will typically be negative
    top :     
    bottom :        
    spine_pos :
        (Default value = -0.05)
    tip_pos :
        (Default value = -0.02)
    orientation :
        (Default value = 'vertical')

    Returns
    -------
        
    """
    # grab the yaxis blended transform
    transform = ax.get_yaxis_transform()

    # add the bracket
    bracket = mpatches.PathPatch(
        mpath.Path(
            [
                [tip_pos, top],
                [spine_pos, top],
                [spine_pos, bottom],
                [tip_pos, bottom],
            ]
        ),
        transform=transform,
        clip_on=False,
        facecolor="none",
        edgecolor="k",
        linewidth=2,
    )
    ax.add_artist(bracket)

    # add the label
    txt = ax.text(
        spine_pos,
        (top + bottom) / 2,
        label,
        ha="right",
        va="center",
        rotation= orientation,
        clip_on=False,
        transform=transform,
    )

    return bracket, txt

def alter_cluster_model(gorder, return_clusters = False):
    """
    Receive a gene order, return True if it behaves according to the alternating gene clusters model.
    Alternative clustering model - groups of more than 2+ protein coding genes that are alternating between the heavy and the light strand.

    Parameters
    ----------
    gorder : list
        List of genes in the exact order they appear on the mtDNA.
    
    Returns
    -------
    : bool
        True if the gorder is arranged in AGC and False if it isnt
    """
    # Remove tRNA
    gorder = [i for i in gorder if 'trn' not in i]
    gcluster = []
    cluster_count = 0
    all_clusters = []
    for gene in gorder:
        # If the current cluster list is empty, add the gene to it
        if gcluster == []:
            gcluster.append(gene)
            continue 
        # Check the current gene's strand and the last gene's strand
        cur_strand = '-' not in gene
        last_strand = '-' not in gcluster[-1]
        # If the current gene is the same strand as the last gene, add to cluster and keep going, otherwise end cluster.
        if cur_strand == last_strand:
            gcluster.append(gene)
        else:
            if len(gcluster) > 1:
                cluster_count += 1
            else:
                return False
            all_clusters.append(gcluster)
            gcluster = []
            gcluster.append(gene)
    all_clusters.append(gcluster)
    if cluster_count >= 2:
        if return_clusters:
            return all_clusters
        return True
    else:
        return False

def sort_x(value, df, cat_a, cat_b, hue, x, y):
    """
    Sort a list of categories (x) according to the pvalue generated by comparing y between hue.
    """
    switched = df.loc[(df[x] == value) & (df[hue] == cat_a), y]
    not_switched = df.loc[(df[x] == value) & (df[hue] == cat_b), y]
    return mannwhitneyu(switched, not_switched, alternative='less').pvalue        

def plot_y_per_x_by_hue(
    df, x, y, figpath = None, hue = 'strand_switch',
    cat_a = 'DSJ',
    cat_b = 'SSJ',
    xlab = 'Organism',
    ylab = 'log(expression)',
    legend_loc = 'lower right',
    add_stats = True,
    test = 'Mann-Whitney',
    multiple_test_correction = True,
    verbose = 1,
    stat_y = None,
    title = '',
    style = 'default',
    despine = True):
    """
    Create a nice looking box plot to compare the values of y between hue for each x.
    Default is comparisons of the junc_tpm expression between DSJ and SSJ for each organism.

    Parameters
    ----------
    df : pd.DataFrame
        The dataframe to plot
    x : str
        The column to plot on the x-axis
    y : str
        The column to plot on the y-axis
    figpath : str
        The path to save the figure to
    hue : str
        The column to group by
    cat_a : str
        The first category to compare
    cat_b : str
        The second category to compare
    xlab : str
        The label for the x-axis
    ylab : str
        The label for the y-axis
    legend_loc : str
        The location of the legend
    add_stats : bool
        Whether to add the p-value and t-statistics to the plot
    test : str
        The statistical test to use
    multiple_test_correction : bool
        Whether to use the Bonferroni correction
    verbose : int
        The verbosity level
    stat_y : str
        The column to use for the statistics
    title : str
        The title of the plot
    
    Returns
    -------
    fig : matplotlib.figure.Figure
        The figure object
    
    """
    plt.style.use(style)
    if not stat_y: stat_y = y
    to_plot = df.replace('_', ' ', regex = True)
    order = sorted([i for i in to_plot[x].unique()], key = lambda w : sort_x(value = w, df = to_plot, cat_a = cat_a, cat_b = cat_b, hue = hue, x = x, y = y), reverse = False)
    box_pairs = [((org, cat_a),(org, cat_b)) for org in to_plot[x].unique()]
    _, ax = plt.subplots(figsize = (8,6))
    sns.boxplot(ax = ax, data = to_plot, y = y, x = x, hue = hue, orient = 'v', order = order, palette = ['#f54245', '#4287f5'])
    if add_stats:
        ax, _ = add_stat_annotation(ax, data = to_plot, y = stat_y,
                        x = x, hue = hue, box_pairs = box_pairs, loc = 'inside', test = test, verbose = verbose,
                    text_format = 'star', comparisons_correction = 'bonferroni' if multiple_test_correction else None, order = order)

    plt.xticks(rotation = 90, fontsize = 11)
    plt.xlabel(xlab, fontsize = 16)
    plt.ylabel(ylab, fontsize = 16)
    plt.title(title, fontsize = 16)
    plt.legend(loc = legend_loc)
    plt.tight_layout()
    if despine:
        sns.despine(ax = ax, right = True, top = True, trim = True)
    if figpath:
        plt.savefig(figpath, dpi = 300)


def gene_junc_type(row, df, org_col = 'org', junctype_col = 'strand_switch', DSJ_name = 'DSJ'):
    """
    """
    org_df = df.loc[(df[org_col] == row[org_col]) & (df[junctype_col] == DSJ_name), :]
    left_genes = list(set(org_df['left_gene'].squeeze()))
    right_genes = list(set(org_df['right_gene'].squeeze()))
    all_genes = left_genes + right_genes
    return 'DSJ' if row.gene in all_genes else 'SSJ'

def generate_2_x_2_conting(
    df,
    row_cat = 'Alter_model',
    comparison_cat = 'strand_switch',
    col_cat_A = 'DSJ',
    col_cat_B = 'SSJ',
    group_factor = 'org',
    cont_factor = 'junc_tpm'):
    """
    Generate a 2x2 chi_squared table for the following factors: significant/non significant and the row_cat.
    The p-values are generated by comparing the cont_factor values between two categories of comparison_cat for each group_factor category.
    """
    AGC_list = []
    non_AGC_list = []
    alpha = 0.05/len(df[group_factor].unique())
    for i in df[group_factor].unique():
        grp_1 = df.loc[(df[comparison_cat] == col_cat_A) & (df[group_factor] == i), cont_factor]
        grp_2 = df.loc[(df[comparison_cat] == col_cat_B) & (df[group_factor] == i), cont_factor]
        AGC = df.loc[df[group_factor] == i, row_cat].iloc[0].squeeze()
        sign = mannwhitneyu(grp_1, grp_2, alternative = 'less').pvalue < alpha
        if AGC:
            AGC_list.append(sign)
        else:
            non_AGC_list.append(sign)
    return np.array([[sum(AGC_list), len(AGC_list) - sum(AGC_list)], [sum(non_AGC_list), len(non_AGC_list) - sum(non_AGC_list)]])

def log2fc(list1, list2, log2 = True):
    """
    Calculate the log2 fold change of the means of list1 to list2.
    """
    if log2:
        return np.log2(np.mean(list1)/np.mean(list2))
    else:
        return np.mean(list1)/np.mean(list2)

def per_pos_log2fc(df_1, df_2, pos_col = 'Position', expr_col = 'RPM', pos_expr_col = 'pos_RPM', neg_expr_col = 'neg_RPM', log2 = True):
    """
    Calculate the per position log2fold change of df_1 to df_2.
    """
    merged = df_1[[pos_col, expr_col, pos_expr_col, neg_expr_col]].merge(df_2[[pos_col, expr_col, pos_expr_col, neg_expr_col]], on = [pos_col], how = 'inner', suffixes = ('_1', '_2'))
    if log2:
        merged['log2fc'] = np.log2((merged[expr_col + '_1'] + 1)/(merged[expr_col + '_2'] + 1))
        merged['pos_log2fc'] = np.log2((merged[pos_expr_col + '_1'] + 1)/(merged[pos_expr_col + '_2'] + 1))
        merged['neg_log2fc'] = np.log2((merged[neg_expr_col + '_1'] + 1)/(merged[neg_expr_col + '_2'] + 1))
    else:
        merged['log2fc'] = (merged[expr_col + '_1'] + 1)/(merged[expr_col + '_2'] + 1)
        merged['pos_log2fc'] = (merged[pos_expr_col + '_1'] + 1)/(merged[pos_expr_col + '_2'] + 1)
        merged['neg_log2fc'] = (merged[neg_expr_col + '_1'] + 1)/(merged[neg_expr_col + '_2'] + 1)
    return merged

def log2fc_sd(list1, list2):
    """
    Calculate the fold change of the std of list1 to list2.
    """
    # Calculate the log2 fold change for all combinations of the two lists
    log2fc_list = []
    for i in list1:
        for j in list2:
            log2fc_list.append(np.log2(i/j))
    return np.std(log2fc_list, ddof = 1)

def get_pairs(x):
    """
    Returns a list of pairs of genes in a list
    """
    try:x = literal_eval(x)
    except ValueError:pass
    return [f'{i}_{j}' for i, j in zip(x, x[1:])]

def combine_annotated_pileup(org, saveloc = 'combined_annotated_pileups'):
    """
    """
    org_initials = ''.join([i[0] for i in org.replace('_',' ').split(' ')]).upper()
    saveloc = os.path.join(PATH, 'data', saveloc)
    if os.path.exists(os.path.join(saveloc, f'{org}_agg_counts.csv')):
        print(f'Combined file for {org} already exists!')
        annotated_df = pd.read_csv(os.path.join(saveloc, f'{org}_agg_counts.csv'), index_col = 0)
        return annotated_df
    
    if not os.path.exists(saveloc):
        os.mkdir(saveloc)
    all_files = glob.glob(os.path.join('data', 'annotated_pileup', f"*{org_initials}.csv"))
    if all_files == []:
        return None
    li = []
    c=0
    real_id = ''
    for filename in all_files:
        #Count organisms
        try: df = pd.read_csv(filename, index_col=0, header=0) # Read in the csv file
        except pd.EmptyDataError: continue # If the file is empty, skip it
        try: id = df.Chromosome.dropna().iloc[0] # Get the RefSeq ID
        except IndexError:
            continue
        if real_id == '':
            cur_org = '_'.join(SeqIO.read(retrieve_gb(id), 'gb').features[0].qualifiers.get('organism')[0].replace(' ', '_').split('_')[0:2]) # Get the organism name based on the RefSeq ID
            if cur_org == org: # If the organism is the same as the one we are looking for, save the RefSeq ID
                real_id = id
            else:
                continue
        else:
            if real_id != id: # If the RefSeq ID is not the same as the one we are looking for, skip the file
                #print(f'Wrong ID {id}')
                continue
        df['org'] = org 
        li.append(df)
        c+=1
    if li == []:
        print('None')
        return None
    #Combine all sample junction dfs to a single one
    annotated_df = pd.concat(li, axis=0)
    agg_dict = {
        'coverage' : 'sum',
        'pos_coverage' : 'sum',
        'neg_coverage' : 'sum',
        'end_start_counts' : 'sum',
        'pos_end_start_counts' : 'sum',
        'neg_end_start_counts' : 'sum',
        'ends_ratio' : 'mean',
        'Feature' : 'first',
        'Gene' : 'first',
        'Length' : 'first',
        'Strand' : 'first',
        'dataset' : 'first'}
    annotated_df = annotated_df.groupby('Position').agg(agg_dict).reset_index()
    annotated_df['end_start_log_ratio'] = np.log10((annotated_df['end_start_counts'] + 1)/(annotated_df['coverage'] + 1))
    annotated_df['pos_end_start_log_ratio'] = np.log10((annotated_df['pos_end_start_counts'] + 1)/(annotated_df['pos_coverage'] + 1))
    annotated_df['neg_end_start_log_ratio'] = np.log10((annotated_df['neg_end_start_counts'] + 1)/(annotated_df['neg_coverage'] + 1))
    annotated_df['organism'] = org
    # Save the annotated_df to a csv file
    annotated_df.to_csv(os.path.join(saveloc, f'{org}_agg_counts.csv'), index=True)
    return annotated_df

def convert_to_asterisk(pvalue):
    """
    Convert a given p-value float to asterisks based on the scientific convention
    """
    if pvalue <= 0.0001:
        return '***'
    elif pvalue <= 0.001:
        return '**'
    elif pvalue <= 0.05:
        return '*'
    else:
        return ' '

def unite_samples_from_folder(folder):
  annot = os.path.join(PATH, 'data', folder, '*.csv')
  annot_df_list = [pd.read_csv(f, index_col = 0) for f in glob.glob(annot)]
  annot_df = pd.concat(annot_df_list, axis = 0)
  test = annot_df.groupby('Position').agg({'pos_end_start_counts' : 'sum', 'neg_end_start_counts' : 'sum', 'end_start_counts' :'sum', 'coverage' : 'sum', 'neg_coverage' : 'sum', 'pos_coverage' :'sum', 'Feature' : 'first', 'Gene' : 'first','Length' : 'first', 'Strand' : 'first', 'dataset' : 'first', 'RPM' : 'mean', 'neg_RPM' : 'mean', 'pos_RPM' : 'mean'}).reset_index()
  test['end_to_coverage'] =np.log2( (test['end_start_counts'] + 1) / (test['coverage'] + 1))
  test['pos_end_to_coverage'] =np.log2( (test['pos_end_start_counts'] + 1) / (test['pos_coverage'] + 1))
  test['neg_end_to_coverage'] =np.log2( (test['neg_end_start_counts'] + 1) / (test['neg_coverage'] + 1))
  return test

def flip_strands(df):
    """
    Flip the strands of the dataframe
    """
    pos = df[[i for i in df.columns if 'pos' in i]]
    neg = df[[i for i in df.columns if 'neg' in i]]
    for col in df.columns:
        if 'pos' in col:
            df[col] = neg[col.replace('pos','neg')]
        elif 'neg' in col:
            df[col] = pos[col.replace('neg','pos')]
    return df
        
def check_if_trna(gpair, gorder):
    """
    Check if a non-tRNA gene junction contains a tRNA gene(s) somewhere between the genes in the gpair
    """
    gpair = gpair.split('_')
    gpair = [Which_tRNA(i) for i in gpair]
    gorder = [i.replace('-', '').replace('*', '') for i in gorder]
    for i, v in enumerate(gorder):
        if v == gpair[0]:
            try:
                if gorder[i + 1] == gpair[1]:
                    return False
                else:
                    return True
            except IndexError: # This means that the gpair[0] gene is the last gene in gorder
                if gorder[0] == gpair[1]:
                    return False
                else:
                    return True

def check_if_trna_wrapper(row):
    """
    Wrapper for check_if_trna to run on df rows
    """
    return check_if_trna(row['gpair'], row['Gene_order'])

def cohen_d(group1, group2):
    """
    Calculate Cohen's d effect size between two groups (group1 - group2)
    
    Parameters
    ----------
    group1 : pandas.Series
        First group of values
    group2 : pandas.Series
        Second group of values
    
    Returns
    -------
    d : float
        Cohen's d effect size
    """
    diff = group1.mean() - group2.mean()
    pooled_var = (group1.std()**3 + group2.std()**3) / 2
    d = diff / np.sqrt(pooled_var)
    return d

def bed_to_per_position_df(bed_df, g_len, keep_cols = []):
    """
    Receive a bed df with the following cols [chr, start, end, ...]
    Convert it into a per-position df with the following cols [Position, is_region] where is_region is a binary 1/0 column depending on whether the position is in the bed file or not
    """
    bed_df['Position'] = bed_df.apply(lambda x: list(range(x['start'], x['end'])), axis=1)
    bed_df = bed_df.explode('Position')
    bed_df['Position'] = bed_df['Position'].astype(int)
    bed_df['is_region'] = 1
    bed_df = bed_df[['Position', 'is_region'] + keep_cols].drop_duplicates(subset = 'Position')

    bed_df = bed_df.set_index('Position').reindex(range(1, g_len + 1)).reset_index().fillna(0)
    return bed_df

def per_position_to_bed(df, reg_col = 'is_region', pos_col = 'Position'):
    """
    Receive a per-position df with the following cols [Position, is_region] where is_region is a binary 1/0 column depending on whether the position is in the bed file or not
    """
    bed_df = {'start' : [], 'end' : []}
    df = df[[reg_col, pos_col]].astype(int)
    df = df[df[reg_col] != 0]
    last_pos = 0

    for i, v in df.iterrows():
        if i == 0:
            last_pos = v[pos_col]
            bed_df['start'].append(v[pos_col])
        elif v[pos_col] == last_pos + 1:
            last_pos = v[pos_col]
        else:
            if last_pos != 0:
                bed_df['end'].append(last_pos + 1)
            bed_df['start'].append(v[pos_col])
            last_pos = v[pos_col]
    bed_df['end'].append(last_pos + 1)
    bed_df = pd.DataFrame(bed_df)
    bed_df['chr'] = 'chrM'
    return bed_df[['chr', 'start', 'end']]

def find_cov_shift(df_grouped, window, strand, pos_col = 'Position', treatment = 'Hypoxia', control = 'Control',  thresh_ratio_to_window = .9):
    """
    Recieve a grouped_df and find the position where the coverage shifts between treatment and control per strand.
    """
    length = df_grouped[pos_col].max()
    df_grouped['diff'] = df_grouped[control] - df_grouped[treatment]
    df_grouped['signet'] = df_grouped['diff'].apply(lambda x: 1 if x > 0 else -1)
    rolling_signet_list = []
    for i in df_grouped[pos_col]:
        region = mtdna_region(i, window,length, left = not strand)
        rolling_signet_list.append(df_grouped.loc[df_grouped[pos_col].isin(region), 'signet'].sum())
    df_grouped['rolling_signet'] = rolling_signet_list
    df_grouped['threshold'] = df_grouped['rolling_signet'].apply(lambda x: 1 if x > thresh_ratio_to_window * window else 0)
    thresh = df_grouped[[pos_col, 'threshold']].sort_values(['threshold', pos_col], ascending = [False, strand]).head(1)[pos_col].values[0]
    return thresh

def find_cov_shift_main(df, window, cov_col = 'RPM', pos_col = 'Position', treatment = 'Hypoxia', control = 'Control', treat_col = 'treatment', thresh_ratio_to_window = .9):
    """
    Receive a df, find the position where the coverage shifts between treatment and control per strand.
    Return the position of the shift for each strand.
    """
    df_grouped = df.groupby([pos_col, treat_col])[[f'pos_{cov_col}', f'neg_{cov_col}']].mean().unstack()
    pos = df_grouped[f'pos_{cov_col}'].reset_index()
    neg = df_grouped[f'neg_{cov_col}'].reset_index()
    pos_thresh = find_cov_shift(pos, window, True, pos_col = pos_col, treatment = treatment, control = control, thresh_ratio_to_window = thresh_ratio_to_window)
    neg_thresh = find_cov_shift(neg, window, False, pos_col = pos_col, treatment = treatment, control = control, thresh_ratio_to_window = thresh_ratio_to_window)
    return pos_thresh, neg_thresh

def assign_treatment(ID):
    """
    Assign the treatment based on the ID using my formula.
    First letter: cell line abbreviation
    Second letter: replicate letter
    Third letter: treatment abbreviation
    """
    # Isolate the sample ID
    ID = ID.split('_')
    # Find which item in list is the sample ID
    for i in ID:
        if len(i) == 3 and i.upper() == i:
            ID = i
    if ID[2] == 'C':
        return 'Control'
    elif ID[2] == 'H':
        return 'Hypoxia'
    elif ID[2] == 'N':
        return 'Normoxia'
    else:
        return 'Unknown'

# Provide a list of positions and a df, set each of the given positions as a focal point with N/2 positions to the left and right, return a df with the focal point and the N positions to the left and right
def get_focal_points(positions, df, N = 10):
    new = []
    for pos in positions:
        left_positions = mtdna_region(pos = pos, window = N//2, total = 16569, left = True, inclusive = False)
        right_positions = mtdna_region(pos = pos, window = N//2, total = 16569, left = False, inclusive = True)
        left_rel_positions = [-1 * i for i  in reversed(range(1, len(left_positions) + 1))]
        right_rel_positions = [i for i, _ in enumerate(right_positions)]
        window_positions = left_positions + right_positions
        window_rel_positions = left_rel_positions + right_rel_positions
        cur_df = df[df['Position'].isin(window_positions)]
        cur_df.loc[:,'relative_position'] = window_rel_positions
        cur_df.loc[:,'focal_point'] = pos
        new.append(cur_df)
    return pd.concat(new, axis = 0)

def plot_around_focal_point(dfs, y, neg_sites_df, pos_sites_df, iterate_col = 'cell', no_treatment = False, treat_col = 'treatment', ctrl_cond = 'Control', treat_cond = 'Hypoxia', figsize = (10, 20), savefig = True, add_to_savefig = '', peak_type_col = 'Type', ylabel ='', xlabel = '', wanted_type = 'Pause', point_pos_col = 'focal_point', rel_pos_col = 'relative_position',
summary_dict = {'neg_ctrl_pause_sites' : [], 'neg_hypoxia_pause_sites':[], 'pos_ctrl_pause_sites' : [], 'pos_hypoxia_pause_sites' : [], 'cell' : []}, alpha = .5
):
    """
    Plot the data around a focal point for each cell line and treatment condition.
    """
    strand_name_dict = {'pos' : 'Heavy', 'neg' : 'Light'}
    plt.style.use('default')
    for ind, strand in enumerate(['pos', 'neg']):
        _, axes = plt.subplots(len(dfs[iterate_col].unique()), 1 if no_treatment else 2, figsize=figsize)
        
        for i, cell in enumerate(dfs[iterate_col].unique()):
            # Filter data
            if strand == 'neg' and not no_treatment:
                cur_df_hypoxia = neg_sites_df[
                    (neg_sites_df[iterate_col] == cell) & 
                    (neg_sites_df[treat_col] == treat_cond)
                ]
                cur_df_control = neg_sites_df[
                    (neg_sites_df[iterate_col] == cell) & 
                    (neg_sites_df[treat_col] == ctrl_cond)
                ]
            elif strand == 'pos' and not no_treatment:
                cur_df_hypoxia = pos_sites_df[
                    (pos_sites_df[iterate_col] == cell) & 
                    (pos_sites_df[treat_col] == treat_cond)
                ]
                cur_df_control = pos_sites_df[
                    (pos_sites_df[iterate_col] == cell) & 
                    (pos_sites_df[treat_col] == ctrl_cond)
                ]
            elif strand == 'neg' and no_treatment:
                cur_df_hypoxia = neg_sites_df[
                    (neg_sites_df[iterate_col] == cell)
                ]
            elif strand == 'pos' and no_treatment:
                cur_df_hypoxia = pos_sites_df[
                    (pos_sites_df[iterate_col] == cell)
                ]
            
            if no_treatment:
                pauses = len(cur_df.loc[cur_df[peak_type_col] == wanted_type, point_pos_col].unique())
            else:
                hypx_pauses = len(cur_df_hypoxia.loc[cur_df_hypoxia[peak_type_col] == wanted_type, point_pos_col].unique())
                ctrl_pauses = len(cur_df_control.loc[cur_df_control[peak_type_col] == wanted_type, point_pos_col].unique())

            # Add to summary df
            if no_treatment:
                summary_dict[f'{strand}_ctrl_pause_sites'].append(pauses)
            else:
                summary_dict[f'{strand}_ctrl_pause_sites'].append(ctrl_pauses)
                summary_dict[f'{strand}_hypoxia_pause_sites'].append(hypx_pauses)
            if ind ==0 :
                summary_dict[iterate_col].append(cell)

            # Plot hypoxia data
            for type_name, group in cur_df_hypoxia.groupby(peak_type_col):
                cur_ax = axes[i] if no_treatment else axes[i, 0]
                # Calculate mean and std for each relative_position
                stats = group.groupby(rel_pos_col)[f'{strand}_{y}'].agg(['mean', 'sem']).reset_index()
                
                # Plot mean line
                line = cur_ax.plot(stats[rel_pos_col], stats['mean'], label=type_name)
                color = line[0].get_color()
                
                # Add confidence bands
                cur_ax.fill_between(
                    stats[rel_pos_col],
                    stats['mean'] - stats['sem'],
                    stats['mean'] + stats['sem'],
                    alpha=0.2,
                    color=color
                )
                # Add line at y=0
                cur_ax.axvline(0, color='black', linestyle='--', alpha = alpha)
            
            if not no_treatment:
                # Plot control data
                for type_name, group in cur_df_control.groupby(peak_type_col):
                    # Calculate mean and std for each relative_position
                    stats = group.groupby(rel_pos_col)[f'{strand}_{y}'].agg(['mean', 'sem']).reset_index()
                    
                    # Plot mean line
                    line = axes[i, 1].plot(stats[rel_pos_col], stats['mean'], label=type_name)
                    color = line[0].get_color()
                    
                    # Add confidence bands
                    axes[i, 1].fill_between(
                        stats[rel_pos_col],
                        stats['mean'] - stats['sem'],
                        stats['mean'] + stats['sem'],
                        alpha=0.2,
                        color=color
                    )
                    # Add line at y=0
                    axes[i, 1].axvline(0, color='black', linestyle='--', alpha = alpha)
            # Add titles and labels            
            if no_treatment:
                axes[i].set_title(f'{strand_name_dict[strand]} Strand - {cell.capitalize()}')
                if ylabel == '':
                    axes[i].set_ylabel(' '.join(y.split('_')).capitalize())
                else:
                    axes[i].set_ylabel(ylabel)
                if xlabel == '':
                    axes[i].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                else:
                    axes[i].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                # Handle legends
                axes[i].legend()
            else:
                axes[i, 0].set_title(f'{strand_name_dict[strand]} Strand - {cell.capitalize()} - {treat_cond}')
                axes[i, 1].set_title(f'{strand_name_dict[strand]} Strand - {cell.capitalize()} - {ctrl_cond}')
                if ylabel == '':
                    axes[i, 0].set_ylabel(' '.join(y.split('_')).capitalize())
                    axes[i, 1].set_ylabel(' '.join(y.split('_')).capitalize())
                else:
                    axes[i, 0].set_ylabel(ylabel)
                    axes[i, 1].set_ylabel(ylabel)
                if xlabel == '':
                    axes[i, 0].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                    axes[i, 1].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                else:
                    axes[i, 0].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                    axes[i, 1].set_xlabel(' '.join(rel_pos_col.split('_')).capitalize())
                
                # Handle legends
                axes[i, 0].legend()
        sns.despine()
        plt.tight_layout()
        # Savefig
        if savefig:
            plt.savefig(os.path.join(PATH, 'proseq', 'figures', 'around_focal_point', f'{strand}_{y}_around_{wanted_type.lower()}_{add_to_savefig + "_" if add_to_savefig != "" else add_to_savefig}sites.png'), dpi=300)
    return pd.DataFrame(summary_dict)